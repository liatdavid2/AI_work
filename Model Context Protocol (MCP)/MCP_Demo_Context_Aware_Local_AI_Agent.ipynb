{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Project: Model Context Protocol (MCP) Demo\n",
        "\n",
        "This project demonstrates how a local AI agent can communicate with a small **Model Context Protocol (MCP)** server to retrieve relevant context and reason about it — all running entirely inside Google Colab, with no external APIs.\n",
        "\n",
        "## How It Works\n",
        "\n",
        "1. **MCP Context Server**\n",
        "   - A simple FastAPI server listens for POST requests at `/mcp/context`.\n",
        "   - When the agent sends a query (for example, \"analyze latest CVE vulnerabilities\" or \"patient symptoms\"),  \n",
        "     the server returns a structured context object that includes:\n",
        "     - The topic (e.g., cybersecurity, health)\n",
        "     - A list of related documents\n",
        "     - A short summary\n",
        "\n",
        "2. **Local Reasoning Agent**\n",
        "   - A lightweight SentenceTransformer model (`all-MiniLM-L6-v2`) runs locally.\n",
        "   - It compares the query and the documents using **cosine similarity** to find which document is most relevant.\n",
        "   - The agent then prints a short explanation describing its reasoning.\n",
        "\n",
        "3. **End-to-End Flow**\n",
        "   - The agent sends a query → MCP returns structured context →  \n",
        "     the agent interprets it → prints the reasoning result.\n",
        "\n",
        "## Example Output\n",
        "\n",
        "For a query such as **“patient shows low mood and sleep problems”**,  \n",
        "the system outputs something like:\n",
        "\n",
        "=== Retrieved Context ===\n",
        "{\n",
        "\"topic\": \"health\",\n",
        "\"related_docs\": [\n",
        "\"Symptoms: fatigue, sleep issues, low mood\",\n",
        "\"Possible diagnosis: mild depression\"\n",
        "],\n",
        "\"summary\": \"Patient shows consistent mood-related symptoms.\"\n",
        "}\n",
        "\n",
        "=== Local Explanation ===\n",
        "Based on context topic 'health', the agent found that:\n",
        "-> Patient shows consistent mood-related symptoms.\n",
        "-> Most relevant info: Symptoms: fatigue, sleep issues, low mood\n",
        "\n",
        "\n",
        "## Key Points\n",
        "\n",
        "- Runs fully locally inside Colab (no ngrok required).\n",
        "- Demonstrates **MCP communication** and **context-aware reasoning**.\n",
        "- Simple and modular — can be extended to real data sources like NVD (cybersecurity) or PubMed (medical).\n"
      ],
      "metadata": {
        "id": "Axjy4UFqbd6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jg4BgRA4XZY8"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q fastapi uvicorn pyngrok nest_asyncio requests sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 – Define the MCP context server"
      ],
      "metadata": {
        "id": "pAcW5qWQXkfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ngrok token from local file \"env_ngrok\"\n",
        "# The file should contain a line: NGROK_AUTH_TOKEN=your_token_here\n",
        "load_dotenv(\"env_ngrok\")\n",
        "ngrok_token = os.getenv(\"NGROK_AUTH_TOKEN\")"
      ],
      "metadata": {
        "id": "y_nP1CnQaSWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any previous Uvicorn processes that are still bound to port 8000\n",
        "import os\n",
        "os.system(\"fuser -k 8000/tcp || echo 'no previous process'\")"
      ],
      "metadata": {
        "id": "_8sRE-JHaVhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MCP Demo – Context-Aware Local AI Agent\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Imports\n",
        "# ------------------------------------------------------------\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import requests\n",
        "from fastapi import FastAPI, Request\n",
        "import uvicorn\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Define the MCP Context Server\n",
        "# ------------------------------------------------------------\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/mcp/context\")\n",
        "async def get_context(request: Request):\n",
        "    \"\"\"Return structured context information based on the query\"\"\"\n",
        "    data = await request.json()\n",
        "    query = data.get(\"query\", \"\").lower()\n",
        "\n",
        "    if \"cve\" in query or \"vulnerability\" in query:\n",
        "        context = {\n",
        "            \"topic\": \"cybersecurity\",\n",
        "            \"related_docs\": [\n",
        "                \"CVE-2025-1234: Privilege escalation in kernel module\",\n",
        "                \"CVE-2024-8791: SQL injection in login endpoint\"\n",
        "            ],\n",
        "            \"summary\": \"Recent critical vulnerabilities require patching in web systems.\"\n",
        "        }\n",
        "    elif \"patient\" in query or \"symptom\" in query:\n",
        "        context = {\n",
        "            \"topic\": \"health\",\n",
        "            \"related_docs\": [\n",
        "                \"Symptoms: fatigue, sleep issues, low mood\",\n",
        "                \"Possible diagnosis: mild depression\"\n",
        "            ],\n",
        "            \"summary\": \"Patient shows consistent mood-related symptoms.\"\n",
        "        }\n",
        "    else:\n",
        "        context = {\n",
        "            \"topic\": \"general\",\n",
        "            \"related_docs\": [\"No domain-specific context found.\"],\n",
        "            \"summary\": \"Query not recognized; generic context returned.\"\n",
        "        }\n",
        "\n",
        "    return {\"query\": query, \"context\": context}\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Start the FastAPI Server in Background (Colab-safe)\n",
        "# ------------------------------------------------------------\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"error\")\n",
        "\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Define Local Agent Logic\n",
        "# ------------------------------------------------------------\n",
        "MCP_URL = \"http://127.0.0.1:8000\"\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def get_mcp_context(query):\n",
        "    \"\"\"Send query to the MCP server and return context\"\"\"\n",
        "    payload = {\"query\": query}\n",
        "    resp = requests.post(MCP_URL + \"/mcp/context\", json=payload)\n",
        "    return resp.json()[\"context\"]\n",
        "\n",
        "def local_reasoner(query):\n",
        "    \"\"\"Simulate a reasoning agent that uses context from MCP\"\"\"\n",
        "    ctx = get_mcp_context(query)\n",
        "    docs = ctx[\"related_docs\"]\n",
        "    embeddings = model.encode([query] + docs, convert_to_tensor=True)\n",
        "    sim = util.cos_sim(embeddings[0], embeddings[1:])\n",
        "    best_idx = int(sim.argmax())\n",
        "\n",
        "    print(\"\\n=== Query ===\")\n",
        "    print(query)\n",
        "    print(\"\\n=== Retrieved Context ===\")\n",
        "    print(ctx)\n",
        "    print(\"\\n=== Best Matched Document ===\")\n",
        "    print(docs[best_idx])\n",
        "    print(\"\\n=== Local Explanation ===\")\n",
        "    print(f\"Based on context topic '{ctx['topic']}', the agent found that:\")\n",
        "    print(f\"-> {ctx['summary']}\")\n",
        "    print(f\"-> Most relevant info: {docs[best_idx]}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Example Runs\n",
        "# ------------------------------------------------------------\n",
        "local_reasoner(\"analyze latest CVE vulnerabilities\")\n",
        "local_reasoner(\"patient shows low mood and sleep problems\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOqOfUFfZ11j",
        "outputId": "0e740782-80f0-41ce-f9d3-3b062e304601"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Query ===\n",
            "analyze latest CVE vulnerabilities\n",
            "\n",
            "=== Retrieved Context ===\n",
            "{'topic': 'cybersecurity', 'related_docs': ['CVE-2025-1234: Privilege escalation in kernel module', 'CVE-2024-8791: SQL injection in login endpoint'], 'summary': 'Recent critical vulnerabilities require patching in web systems.'}\n",
            "\n",
            "=== Best Matched Document ===\n",
            "CVE-2025-1234: Privilege escalation in kernel module\n",
            "\n",
            "=== Local Explanation ===\n",
            "Based on context topic 'cybersecurity', the agent found that:\n",
            "-> Recent critical vulnerabilities require patching in web systems.\n",
            "-> Most relevant info: CVE-2025-1234: Privilege escalation in kernel module\n",
            "\n",
            "=== Query ===\n",
            "patient shows low mood and sleep problems\n",
            "\n",
            "=== Retrieved Context ===\n",
            "{'topic': 'health', 'related_docs': ['Symptoms: fatigue, sleep issues, low mood', 'Possible diagnosis: mild depression'], 'summary': 'Patient shows consistent mood-related symptoms.'}\n",
            "\n",
            "=== Best Matched Document ===\n",
            "Symptoms: fatigue, sleep issues, low mood\n",
            "\n",
            "=== Local Explanation ===\n",
            "Based on context topic 'health', the agent found that:\n",
            "-> Patient shows consistent mood-related symptoms.\n",
            "-> Most relevant info: Symptoms: fatigue, sleep issues, low mood\n"
          ]
        }
      ]
    }
  ]
}