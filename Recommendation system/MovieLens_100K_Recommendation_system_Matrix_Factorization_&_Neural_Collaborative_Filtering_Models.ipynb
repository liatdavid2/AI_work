{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z75X-qQy3wRw"
   },
   "source": [
    "# The Project\n",
    "\n",
    "The project focuses on building and evaluating **recommender systems** using two types of models:\n",
    "\n",
    "1. **Matrix Factorization Models (SVD, SVD++, ALS):**  \n",
    "   - Decompose the user–item rating matrix into latent factors.  \n",
    "   - Capture underlying patterns in user preferences and item characteristics.  \n",
    "   - Provide accurate rating predictions and serve as strong baselines in recommender systems research.  \n",
    "\n",
    "2. **Neural Collaborative Filtering Models (NCF, NeuMF):**  \n",
    "   - Replace linear factorization with neural networks to learn non-linear interactions.  \n",
    "   - Combine embeddings of users and items through deep layers (MLP) or hybrid architectures (NeuMF = GMF + MLP).  \n",
    "   - Aim to outperform traditional matrix factorization by modeling complex relationships.  \n",
    "\n",
    "The comparison of these two families of models demonstrates the evolution of recommender systems from classical approaches to modern deep learning methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Q4UuZJ3yzP"
   },
   "source": [
    "# Dataset: MovieLens 100K\n",
    "\n",
    "The experiments are based on the **MovieLens 100K dataset**, a widely used benchmark in recommender systems research.  \n",
    "\n",
    "- **Size:** 100,000 ratings  \n",
    "- **Users:** 943  \n",
    "- **Movies:** 1,682  \n",
    "- **Format:** tab-delimited files (CSV-like)\n",
    "\n",
    "## Main Columns\n",
    "- **userId** – unique identifier of each user (anonymized, 1–943).  \n",
    "- **movieId** – unique identifier of each movie (1–1682).  \n",
    "- **rating** – explicit rating from 1 to 5, where higher values indicate stronger preference.  \n",
    "- **timestamp** – UNIX time indicating when the rating was made.  \n",
    "- **title** (from `u.item`) – the name of the movie.  \n",
    "- **genres** (from `u.item`) – one or more genres assigned to each movie (e.g., Action, Comedy).  \n",
    "\n",
    "This dataset is small enough to allow fast experimentation, yet rich enough to demonstrate the strengths and weaknesses of different recommendation algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqq0Es59wzkO"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y scikit-surprise\n",
    "!pip install numpy==1.26.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UsycBN4xvh2"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-surprise --no-binary scikit-surprise --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHOPY2VPuPm2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awX2Kb6Ewx9I",
    "outputId": "5750823b-21f1-4006-9b51-bdde70abbc40"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the ZIP file in Google Drive\n",
    "zip_path = \"/content/drive/MyDrive/Portfolio datasets/Recommender engine/ml-100k.zip\"\n",
    "extract_path = \"/content/ml-100k\"\n",
    "\n",
    "# Extract the dataset\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Load the ratings (u.data)\n",
    "data_path = f\"{extract_path}/ml-100k/u.data\"\n",
    "df = pd.read_csv(\n",
    "    data_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "# Load the movie titles (u.item)\n",
    "item_path = f\"{extract_path}/ml-100k/u.item\"\n",
    "movies = pd.read_csv(\n",
    "    item_path,\n",
    "    sep=\"|\",\n",
    "    encoding=\"latin-1\",\n",
    "    header=None,\n",
    "    usecols=[0, 1],\n",
    "    names=[\"movieId\", \"title\"]\n",
    ")\n",
    "\n",
    "# Merge ratings with movie titles\n",
    "df_merged = pd.merge(df, movies, on=\"movieId\")\n",
    "\n",
    "print(\"Data shape:\", df_merged.shape)\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9BR0pwGwBkn",
    "outputId": "12d420df-e4ff-4784-86e7-992ed6b242ae"
   },
   "outputs": [],
   "source": [
    "print(\"Unique users:\", df_merged[\"userId\"].nunique())\n",
    "print(\"Unique movies:\", df_merged[\"movieId\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGLh3xNGwLRX"
   },
   "source": [
    "# Split by rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "WONlrg51wCeO",
    "outputId": "afcea5e6-309b-4782-d653-7a915010273f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rating_counts = df_merged[\"rating\"].value_counts().sort_index()\n",
    "\n",
    "print(rating_counts)\n",
    "\n",
    "rating_counts.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Ratings in MovieLens 100K\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sJPBGB9wp6-"
   },
   "source": [
    "#Recommender engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obSXrFaPw3le"
   },
   "source": [
    "## Matrix Factorization (SVD / SVD++ / ALS)\n",
    "\n",
    "**How it works:**  \n",
    "Decomposes the user–item rating matrix into latent factors (vectors for users and items).\n",
    "\n",
    "**Advantages:**  \n",
    "- Simple and very powerful  \n",
    "- Serves as the foundation for many real-world recommender engines  \n",
    "\n",
    "**Performance:**  \n",
    "- Excellent results on MovieLens 100K  \n",
    "- RMSE ~0.91–0.94 (SVD++ slightly better than regular SVD)  \n",
    "\n",
    "**Limitation:**  \n",
    "- Difficult to incorporate side information (content, genres, metadata)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzVmaYKfzwOP"
   },
   "source": [
    "# Recommender System Evaluation with Cross-Validation\n",
    "\n",
    "This code evaluates different recommender models (**SVD, SVD++, ALS**) on the **MovieLens 100K** dataset using **5-Fold Cross-Validation**.  \n",
    "It computes both **rating accuracy (RMSE)** and **Top-K recommendation metrics (Precision, Recall, F1, NDCG, HitRate)** for K = 5, 10, 20.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1. Helper Function: `metrics_at_k`\n",
    "- Groups predictions per user.  \n",
    "- For each user:\n",
    "  - Sorts predicted ratings in descending order.  \n",
    "  - Defines \"relevant items\" as those with true rating ≥ 4.  \n",
    "  - For each `k` in {5, 10, 20}:  \n",
    "    - **Precision@k** = relevant recommended / k  \n",
    "    - **Recall@k** = relevant recommended / total relevant  \n",
    "    - **F1@k** = harmonic mean of Precision and Recall  \n",
    "    - **NDCG@k** = quality of ranking (higher weight for relevant items at top)  \n",
    "    - **HitRate@k** = whether at least one relevant item was recommended  \n",
    "\n",
    "The function returns **average metrics across all users**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Preparation\n",
    "- Extracts only `userId`, `movieId`, `rating` from the merged MovieLens dataset.  \n",
    "- Converts into Surprise `Dataset` with ratings in the range 1–5.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Models\n",
    "- **SVD** – basic matrix factorization.  \n",
    "- **SVD++** – improved version using implicit feedback.  \n",
    "- **ALS (BaselineOnly)** – bias-based baseline using Alternating Least Squares.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Cross-Validation Loop\n",
    "- Uses **5-Fold CV** (`KFold(n_splits=5)`).  \n",
    "- For each fold and model:\n",
    "  - Train on trainset, predict on testset.  \n",
    "  - Compute **RMSE** on testset.  \n",
    "  - Compute **Precision, Recall, F1, NDCG, HitRate** for K=5,10,20.  \n",
    "  - Collect metrics across folds.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Final Output\n",
    "\n",
    "| Model          | RMSE (mean) | Precision@5 | Recall@5 | F1@5  | NDCG@5 | HitRate@5 | Precision@10 | Recall@10 | F1@10 | NDCG@10 | HitRate@10 | Precision@20 | Recall@20 | F1@20 | NDCG@20 | HitRate@20 |\n",
    "|----------------|-------------|-------------|----------|-------|--------|-----------|--------------|-----------|-------|---------|-------------|--------------|-----------|-------|---------|-------------|\n",
    "| **SVD**        | **0.9349**  | 0.696       | 0.518    | 0.497 | 0.804  | 0.975     | 0.577        | 0.715     | 0.539 | 0.823   | 0.979       | 0.423        | 0.865     | 0.488 | 0.844   | 0.980       |\n",
    "| **SVD++**      | **0.9195**  | 0.706       | 0.522    | 0.503 | 0.815  | 0.975     | 0.582        | 0.720     | 0.544 | 0.831   | 0.980       | 0.425        | 0.867     | 0.490 | 0.851   | 0.980       |\n",
    "| **ALS (Base)** | **0.9436**  | 0.691       | 0.517    | 0.495 | 0.799  | 0.975     | 0.572        | 0.713     | 0.536 | 0.818   | 0.979       | 0.420        | 0.863     | 0.486 | 0.841   | 0.980       |\n",
    "\n",
    "---\n",
    "\n",
    "## Insights\n",
    "- **SVD++ performed best overall**: lowest RMSE (0.9195) and strongest Top-K metrics (Precision, Recall, NDCG).  \n",
    "- **SVD** was slightly weaker but still strong, with performance close to SVD++.  \n",
    "- **ALS (Baseline)** provided a solid baseline but consistently underperformed compared to SVD and SVD++.  \n",
    "- Across all models:\n",
    "  - **HitRate@5,10,20 ≈ 0.98** → almost every user got at least one relevant recommendation in the top list.  \n",
    "  - **Recall increases with K** (users see more relevant items as K grows).  \n",
    "  - **Precision decreases with K** (top-5 is more precise than top-20).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwrIy4nE0yvG"
   },
   "source": [
    "# Conclusions from Results\n",
    "\n",
    "1. **Overall Performance**\n",
    "   - The models achieved strong performance on the MovieLens 100K dataset.\n",
    "   - All models reached a **HitRate@K ≈ 0.98**, meaning almost every user received at least one relevant recommendation in the top list.\n",
    "\n",
    "2. **Model Comparison**\n",
    "   - **SVD++** delivered the best performance:\n",
    "     - Lowest RMSE (≈ 0.918)\n",
    "     - Highest Precision, Recall, and NDCG across all K values\n",
    "   - **SVD** performed slightly worse (RMSE ≈ 0.936) but remained competitive, showing it is still a strong baseline.\n",
    "   - **ALS (Baseline)** was consistently weaker (RMSE ≈ 0.944) but provides a fast and simple benchmark.\n",
    "\n",
    "3. **Top-K Behavior**\n",
    "   - **Precision@K decreases** as K increases (e.g., ~0.71 at K=5 vs. ~0.42 at K=20).  \n",
    "     → More recommendations mean less accuracy per item.\n",
    "   - **Recall@K increases** with K (e.g., ~0.52 at K=5 vs. ~0.87 at K=20).  \n",
    "     → Longer recommendation lists capture more relevant items.\n",
    "   - **NDCG values** confirm that relevant items are ranked near the top, especially for SVD++.\n",
    "\n",
    "4. **Key Insight**\n",
    "   - **SVD++ is the best choice** for this dataset, balancing both rating prediction accuracy (RMSE) and recommendation quality (Top-K metrics).\n",
    "   - Traditional **SVD** is a solid and simpler alternative.\n",
    "   - **ALS** can serve as a baseline but should not be the final choice for production.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNpK2RIazb4E",
    "outputId": "171e5c59-0df4-409d-e61b-8e40691f47f3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, SVDpp, BaselineOnly, accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Helper: compute metrics for multiple K values ===\n",
    "def metrics_at_k(predictions, ks=[5, 10, 20]):\n",
    "    user_ratings = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_ratings[uid].append((iid, est, true_r))\n",
    "\n",
    "    results = {k: {\"Precision\": [], \"Recall\": [], \"F1\": [], \"NDCG\": [], \"HitRate\": []} for k in ks}\n",
    "\n",
    "    for uid, ratings in user_ratings.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Relevant = rating >= 4\n",
    "        rel = [r for (_, _, r) in ratings if r >= 4]\n",
    "        n_rel = len(rel)\n",
    "\n",
    "        for k in ks:\n",
    "            top_k = ratings[:k]\n",
    "            rec = [iid for (iid, _, r) in top_k if r >= 4]\n",
    "            n_rel_and_rec_k = len(rec)\n",
    "\n",
    "            precision = n_rel_and_rec_k / k if k > 0 else 0\n",
    "            recall = n_rel_and_rec_k / n_rel if n_rel > 0 else 0\n",
    "            f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "\n",
    "            dcg = sum([1 / np.log2(idx+2) for idx, (iid, _, r) in enumerate(top_k) if r >= 4])\n",
    "            idcg = sum([1 / np.log2(idx+2) for idx in range(min(n_rel, k))])\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "            hit = 1 if n_rel_and_rec_k > 0 else 0\n",
    "\n",
    "            results[k][\"Precision\"].append(precision)\n",
    "            results[k][\"Recall\"].append(recall)\n",
    "            results[k][\"F1\"].append(f1)\n",
    "            results[k][\"NDCG\"].append(ndcg)\n",
    "            results[k][\"HitRate\"].append(hit)\n",
    "\n",
    "    # Average across users\n",
    "    return {\n",
    "        k: {m: np.mean(vals) for m, vals in metrics.items()}\n",
    "        for k, metrics in results.items()\n",
    "    }\n",
    "\n",
    "# === Prepare data ===\n",
    "ratings_df = df_merged[[\"userId\", \"movieId\", \"rating\"]]\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_df, reader)\n",
    "\n",
    "# === Models ===\n",
    "models = {\n",
    "    \"SVD\": SVD(),\n",
    "    \"SVD++\": SVDpp(),\n",
    "    \"ALS (Baseline)\": BaselineOnly()\n",
    "}\n",
    "\n",
    "# === Cross-validation ===\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    rmses = []\n",
    "    metrics_all = {5: [], 10: [], 20: []}\n",
    "\n",
    "    for fold, (trainset, testset) in enumerate(kf.split(data), 1):\n",
    "        print(f\" Fold {fold} ...\")\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "\n",
    "        # RMSE\n",
    "        rmse = accuracy.rmse(predictions, verbose=False)\n",
    "        print(f\"   RMSE: {rmse:.4f}\")\n",
    "        rmses.append(rmse)\n",
    "\n",
    "        # Top-K metrics\n",
    "        metrics = metrics_at_k(predictions, ks=[5, 10, 20])\n",
    "        for k in metrics:\n",
    "            metrics_all[k].append(metrics[k])\n",
    "\n",
    "    # Aggregate\n",
    "    row = {\"Model\": name, \"RMSE (mean)\": np.mean(rmses)}\n",
    "    for k in [5, 10, 20]:\n",
    "        avg_metrics = {m+f\"@{k}\": np.mean([fold[m] for fold in metrics_all[k]]) for m in metrics_all[k][0]}\n",
    "        row.update(avg_metrics)\n",
    "    results.append(row)\n",
    "\n",
    "# === Final results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== 5-Fold Cross-Validation Results (Aggregated) ===\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jms5MXYL1YwX"
   },
   "source": [
    "# NeuMF 5-Fold Cross-Validation: Code Overview\n",
    "\n",
    "## What the code does\n",
    "This script trains and evaluates a **NeuMF (Neural Matrix Factorization)** recommender on MovieLens 100K using **5-fold cross-validation**, reporting both **RMSE** and **Top-K ranking metrics**.\n",
    "\n",
    "## Data handling\n",
    "- Expects a pre-built `df_merged` with `userId`, `movieId`, `rating`.\n",
    "- Converts `userId`/`movieId` to zero-based indices.\n",
    "- Wraps samples in a `RatingsDataset` and uses PyTorch `DataLoader` for batching.\n",
    "\n",
    "## Model architecture (NeuMF)\n",
    "- **GMF branch:** user/item embeddings with element-wise product to capture linear interactions.\n",
    "- **MLP branch:** separate user/item embeddings concatenated and passed through fully-connected layers (default hidden sizes: `[64, 32, 16]`) with ReLU.\n",
    "- **Fusion:** concatenation of GMF output and MLP output, followed by a final linear layer to predict a rating.\n",
    "- Default embedding sizes: `emb_size_gmf=32`, `emb_size_mlp=32`.\n",
    "\n",
    "## Training setup\n",
    "- Optimizer: Adam (`lr=0.001`).\n",
    "- Loss: Mean Squared Error (predicting explicit ratings 1–5).\n",
    "- Epochs: `5` per fold.\n",
    "- Batch size: `512`.\n",
    "- For each fold, a **fresh NeuMF model is initialized**, trained, and evaluated.\n",
    "\n",
    "## Evaluation\n",
    "- **RMSE** on the test split of each fold.\n",
    "- **Top-K metrics** computed by `metrics_at_k` for K ∈ {5, 10, 20}:\n",
    "  - Precision@K, Recall@K, F1@K\n",
    "  - NDCG@K\n",
    "  - HitRate@K\n",
    "- An item is considered **relevant** if `true_rating ≥ 4`.\n",
    "- The script prints per-fold results and then an aggregated mean across folds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pknf8eSgA_X6"
   },
   "source": [
    "# NeuMF 5-Fold Cross-Validation: Results and Conclusions\n",
    "\n",
    "## Results\n",
    "\n",
    "### Training and Test RMSE per Fold\n",
    "- **Fold 1:** Final Train RMSE = 0.9789, Test RMSE = 0.9936  \n",
    "- **Fold 2:** Final Train RMSE = 0.9802, Test RMSE = 0.9905  \n",
    "- **Fold 3:** Final Train RMSE = 0.9787, Test RMSE = 0.9999  \n",
    "- **Fold 4:** Final Train RMSE = 0.9801, Test RMSE = 0.9971  \n",
    "- **Fold 5:** Final Train RMSE = 0.9764, Test RMSE = 0.9987  \n",
    "\n",
    "### Averaged Results across 5 Folds\n",
    "- **RMSE:** 0.996  \n",
    "- **Precision@5:** 0.673  \n",
    "- **Recall@5:** 0.505  \n",
    "- **F1@5:** 0.483  \n",
    "- **NDCG@5:** 0.777  \n",
    "- **HitRate@5:** 0.974  \n",
    "- **Precision@10:** 0.559  \n",
    "- **Recall@10:** 0.703  \n",
    "- **F1@10:** 0.525  \n",
    "- **NDCG@10:** 0.798  \n",
    "- **HitRate@10:** 0.979  \n",
    "- **Precision@20:** 0.412  \n",
    "- **Recall@20:** 0.855  \n",
    "- **F1@20:** 0.478  \n",
    "- **NDCG@20:** 0.824  \n",
    "- **HitRate@20:** 0.980  \n",
    "\n",
    "## Conclusions\n",
    "\n",
    "1. **Overall Performance**\n",
    "   - NeuMF achieved stable performance across all folds with consistent RMSE and Top-K metrics.\n",
    "   - HitRate remained very high (≈0.98) for all K, showing nearly every user received at least one relevant recommendation.\n",
    "\n",
    "2. **Accuracy**\n",
    "   - RMSE averaged around 0.996, which is higher (worse) than SVD++ (≈0.918) and SVD (≈0.936).\n",
    "   - Indicates NeuMF did not outperform matrix factorization under this training setup.\n",
    "\n",
    "3. **Top-K Metrics**\n",
    "   - Precision@K decreases as K increases (from ≈0.67 at K=5 down to ≈0.41 at K=20).\n",
    "   - Recall@K increases with K (from ≈0.51 at K=5 up to ≈0.86 at K=20).\n",
    "   - NDCG values confirm that relevant items are ranked relatively high, with best results at K=20.\n",
    "\n",
    "4. **Key Insight**\n",
    "   - While NeuMF provides solid recommendations, its RMSE is worse than classical matrix factorization methods in this experiment.\n",
    "   - With more epochs, larger embeddings, and hyperparameter tuning, NeuMF is expected to improve and potentially surpass SVD++.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k259KTKK44JY",
    "outputId": "c2ff8c9a-2a3f-4e6f-879f-137cf2c232f1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Dataset Wrapper ===\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df[\"userId\"].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df[\"movieId\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "# === NeuMF Model ===\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_size_gmf=32, emb_size_mlp=32, hidden=[64,32,16]):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        # GMF embeddings\n",
    "        self.user_emb_gmf = nn.Embedding(n_users, emb_size_gmf)\n",
    "        self.item_emb_gmf = nn.Embedding(n_items, emb_size_gmf)\n",
    "\n",
    "        # MLP embeddings\n",
    "        self.user_emb_mlp = nn.Embedding(n_users, emb_size_mlp)\n",
    "        self.item_emb_mlp = nn.Embedding(n_items, emb_size_mlp)\n",
    "\n",
    "        # MLP layers\n",
    "        mlp_layers = []\n",
    "        input_size = emb_size_mlp * 2\n",
    "        for h in hidden:\n",
    "            mlp_layers.append(nn.Linear(input_size, h))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            input_size = h\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "        # Final prediction layer\n",
    "        self.output = nn.Linear(emb_size_gmf + hidden[-1], 1)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        gmf_u = self.user_emb_gmf(users)\n",
    "        gmf_i = self.item_emb_gmf(items)\n",
    "        gmf = gmf_u * gmf_i\n",
    "\n",
    "        mlp_u = self.user_emb_mlp(users)\n",
    "        mlp_i = self.item_emb_mlp(items)\n",
    "        mlp = self.mlp(torch.cat([mlp_u, mlp_i], dim=1))\n",
    "\n",
    "        x = torch.cat([gmf, mlp], dim=1)\n",
    "        return self.output(x).squeeze()\n",
    "\n",
    "# === Helper: Top-K metrics ===\n",
    "def metrics_at_k(users, items, ratings, preds, ks=[5,10,20]):\n",
    "    user_ratings = defaultdict(list)\n",
    "    for u, i, r, p in zip(users, items, ratings, preds):\n",
    "        user_ratings[int(u)].append((i, p, r))\n",
    "\n",
    "    results = {k: {\"Precision\": [], \"Recall\": [], \"F1\": [], \"NDCG\": [], \"HitRate\": []} for k in ks}\n",
    "\n",
    "    for uid, ratings in user_ratings.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        rel = [r for (_, _, r) in ratings if r >= 4]\n",
    "        n_rel = len(rel)\n",
    "\n",
    "        for k in ks:\n",
    "            top_k = ratings[:k]\n",
    "            rec = [iid for (iid, _, r) in top_k if r >= 4]\n",
    "            n_rel_and_rec_k = len(rec)\n",
    "\n",
    "            precision = n_rel_and_rec_k / k if k > 0 else 0\n",
    "            recall = n_rel_and_rec_k / n_rel if n_rel > 0 else 0\n",
    "            f1 = (2*precision*recall / (precision+recall)) if (precision+recall)>0 else 0\n",
    "\n",
    "            dcg = sum([1/np.log2(idx+2) for idx,(iid,_,r) in enumerate(top_k) if r>=4])\n",
    "            idcg = sum([1/np.log2(idx+2) for idx in range(min(n_rel, k))])\n",
    "            ndcg = dcg/idcg if idcg>0 else 0\n",
    "\n",
    "            hit = 1 if n_rel_and_rec_k>0 else 0\n",
    "\n",
    "            results[k][\"Precision\"].append(precision)\n",
    "            results[k][\"Recall\"].append(recall)\n",
    "            results[k][\"F1\"].append(f1)\n",
    "            results[k][\"NDCG\"].append(ndcg)\n",
    "            results[k][\"HitRate\"].append(hit)\n",
    "\n",
    "    return {k: {m: np.mean(vals) for m, vals in metrics.items()} for k, metrics in results.items()}\n",
    "\n",
    "# === Load ratings data (from df_merged) ===\n",
    "ratings_df = df_merged[[\"userId\", \"movieId\", \"rating\"]].copy()\n",
    "ratings_df[\"userId\"] -= 1\n",
    "ratings_df[\"movieId\"] -= 1\n",
    "\n",
    "n_users = ratings_df[\"userId\"].nunique()\n",
    "n_items = ratings_df[\"movieId\"].nunique()\n",
    "\n",
    "# === 5-Fold Cross Validation ===\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(ratings_df), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    train_df = ratings_df.iloc[train_idx]\n",
    "    test_df = ratings_df.iloc[test_idx]\n",
    "\n",
    "    train_loader = DataLoader(RatingsDataset(train_df), batch_size=512, shuffle=True)\n",
    "    test_loader = DataLoader(RatingsDataset(test_df), batch_size=512, shuffle=False)\n",
    "\n",
    "    # Init new NeuMF each fold\n",
    "    model = NeuMF(n_users, n_items).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for users, items, ratings in train_loader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(users, items)\n",
    "            loss = criterion(preds, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(ratings)\n",
    "        print(f\"  Epoch {epoch+1}/{epochs}, Train RMSE: {np.sqrt(train_loss/len(train_df)):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_preds, test_truth, test_users, test_items = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in test_loader:\n",
    "            users, items = users.to(device), items.to(device)\n",
    "            preds = model(users, items).cpu().numpy()\n",
    "            test_preds.extend(preds)\n",
    "            test_truth.extend(ratings.numpy())\n",
    "            test_users.extend(users.cpu().numpy())\n",
    "            test_items.extend(items.cpu().numpy())\n",
    "\n",
    "    rmse = np.sqrt(np.mean((np.array(test_preds) - np.array(test_truth))**2))\n",
    "    print(f\"  Fold {fold} RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # Top-K\n",
    "    metrics = metrics_at_k(test_users, test_items, test_truth, test_preds, ks=[5,10,20])\n",
    "\n",
    "    row = {\"Fold\": fold, \"RMSE\": rmse}\n",
    "    for k in [5,10,20]:\n",
    "        for m,v in metrics[k].items():\n",
    "            row[m+f\"@{k}\"] = v\n",
    "    results.append(row)\n",
    "\n",
    "# === Aggregate Results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== NeuMF 5-Fold CV Results (Per Fold) ===\")\n",
    "print(results_df)\n",
    "\n",
    "avg_results = results_df.mean(numeric_only=True)\n",
    "print(\"\\n=== NeuMF 5-Fold CV Results (Averaged) ===\")\n",
    "print(avg_results)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
