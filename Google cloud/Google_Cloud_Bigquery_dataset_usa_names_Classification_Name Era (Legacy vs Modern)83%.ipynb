{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiWipyaSTZB_"
   },
   "source": [
    "### The project: Predicting Name Era (Legacy vs Modern) using Google BigQuery and XGBoost\n",
    "\n",
    "This project aims to **classify given names as either \"Legacy\" (pre-2000) or \"Modern\" (from 2000 onward)** based on historical US birth data, using features extracted from the names themselves. The data was queried directly from the **`bigquery-public-data.usa_names.usa_1910_current`** dataset on **Google Cloud BigQuery**, containing over 1.8 million name records.\n",
    "\n",
    "---\n",
    "\n",
    "### Data & Labeling\n",
    "\n",
    "* We **grouped names by decade**, then selected only names that appeared predominantly in a single decade (to reduce ambiguity).\n",
    "* The decades were then **mapped into binary labels**:\n",
    "\n",
    "  * `Legacy`: Decades ≤ 1990\n",
    "  * `Modern`: Decades ≥ 2000\n",
    "\n",
    "---\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "We extracted both statistical and linguistic features:\n",
    "\n",
    "* **Character-level n-grams (1–3)**\n",
    "* **Name structure features**: length, first/last letters, suffixes, vowel ratios\n",
    "* **Semantic patterns**: starts with \"Mc\", ends with \"n\" or \"a\"\n",
    "* **Popularity trend**: ratio of name’s popularity within its decade\n",
    "\n",
    "All features were combined into a **sparse matrix**, including one-hot encodings for categorical features.\n",
    "\n",
    "---\n",
    "\n",
    "### Modeling & Evaluation\n",
    "\n",
    "* The classifier used is **XGBoost** (tree-based ensemble), trained with:\n",
    "\n",
    "  * Stratified sampling to ensure ≥30 Legacy samples in test set\n",
    "  * **Random oversampling** applied only to the training set to balance class distributions\n",
    "  * **Manual grid search** (64 parameter combinations) to select the best hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "### Results\n",
    "\n",
    "Final evaluation (on test set):\n",
    "\n",
    "* **Accuracy**: 83.46%\n",
    "* **Legacy Recall**: 60%\n",
    "* **Modern Recall**: 91%\n",
    "* **Macro F1**: 0.76\n",
    "\n",
    "This performance indicates the model **successfully learns to distinguish older vs newer name trends**, especially excelling at identifying Modern names, while still retrieving Legacy names with reasonable recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6O8j_hcTSRa"
   },
   "source": [
    "# The dataset: `bigquery-public-data.usa_names.usa_1910_current`\n",
    "\n",
    "This dataset contains historical records of baby names registered in the United States from the year 1910 onwards. It is publicly hosted on Google BigQuery as part of Google's public datasets.\n",
    "\n",
    "## Source\n",
    "\n",
    "The data originates from the U.S. Social Security Administration (SSA) and includes aggregated birth name information by year, gender, and state.\n",
    "\n",
    "## Columns Description\n",
    "\n",
    "| Column   | Type    | Description |\n",
    "|----------|---------|-------------|\n",
    "| `name`   | STRING  | The first name of the baby. |\n",
    "| `gender` | STRING  | The gender associated with the name: either `\"M\"` (Male) or `\"F\"` (Female). |\n",
    "| `state`  | STRING  | The U.S. state abbreviation (e.g., \"CA\", \"NY\"). In some entries this field may be null. |\n",
    "| `year`   | INTEGER | The year in which the name was registered. |\n",
    "| `number` | INTEGER | The number of babies given this name in that year and state. |\n",
    "\n",
    "## Target / Label Column\n",
    "\n",
    "There is no explicit label column in this dataset, as it is not originally designed for supervised machine learning tasks. However, depending on the goal of the analysis, one can define a target. For example:\n",
    "- In a **gender prediction task**, the column `gender` can serve as the label.\n",
    "- For **popularity prediction**, the column `number` or its change over time could be used as a target variable.\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "This dataset is suitable for a variety of data science and analytics tasks, including:\n",
    "- Trend analysis of baby name popularity over time.\n",
    "- Gender distribution of names.\n",
    "- Identification of unisex (gender-neutral) names.\n",
    "- Forecasting future popularity of specific names.\n",
    "- Sociocultural studies (e.g., names influenced by events, celebrities, or politics).\n",
    "\n",
    "## Dataset Characteristics\n",
    "\n",
    "- Total rows: ~1.8 million (depending on filters).\n",
    "- Time range: 1910 to present.\n",
    "- Granularity: Yearly.\n",
    "- Aggregated: Not individual-level data, but grouped by name/year/state/gender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oIDRhEYKLr44"
   },
   "outputs": [],
   "source": [
    "# Step 1: Install requirements (if needed)\n",
    "!pip install -q google-cloud-bigquery xgboost\n",
    "\n",
    "# Step 2: Imports and authentication\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VQ9p_zl-LvqO"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Step 3: Connect to BigQuery and query gender + name data\n",
    "project_id = \"custom-helix-474006-k6\"  # ← replace with your GCP project ID\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFo8-mSvWP3V",
    "outputId": "44655449-7618-43b7-8895-9a3af637192b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from BigQuery...\n",
      "Retrieved 182540 rows.\n",
      "\n",
      "Creating stratified split with minimum Legacy samples...\n",
      "Test set includes 30 Legacy samples.\n",
      "\n",
      "Final Evaluation:\n",
      "Test Accuracy: 83.46 %\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Legacy       0.67      0.60      0.63        30\n",
      "      Modern       0.88      0.91      0.89        97\n",
      "\n",
      "    accuracy                           0.83       127\n",
      "   macro avg       0.77      0.75      0.76       127\n",
      "weighted avg       0.83      0.83      0.83       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Step 1: Query BigQuery\n",
    "print(\"Querying from BigQuery...\")\n",
    "query = \"\"\"\n",
    "SELECT name, year, gender, SUM(number) AS total\n",
    "FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "WHERE year >= 1910\n",
    "GROUP BY name, year, gender\n",
    "HAVING total > 100\n",
    "\"\"\"\n",
    "df = client.query(query).to_dataframe()\n",
    "print(f\"Retrieved {len(df)} rows.\")\n",
    "\n",
    "# Step 2: Prepare decade and filter\n",
    "df[\"decade\"] = (df[\"year\"] // 10) * 10\n",
    "df[\"decade\"] = df[\"decade\"].astype(str)\n",
    "df_grouped = df.groupby([\"name\", \"decade\"], as_index=False)[\"total\"].sum()\n",
    "name_counts = df_grouped.groupby(\"name\")[\"decade\"].nunique().reset_index()\n",
    "df_single = df_grouped[df_grouped[\"name\"].isin(name_counts[name_counts[\"decade\"] == 1][\"name\"])].reset_index(drop=True)\n",
    "valid_decades = df_single[\"decade\"].value_counts()[lambda x: x >= 100].index\n",
    "df_single = df_single[df_single[\"decade\"].isin(valid_decades)].reset_index(drop=True)\n",
    "\n",
    "# Step 3: Binary labeling – Modern vs Legacy\n",
    "df_single[\"era\"] = df_single[\"decade\"].apply(lambda d: \"Modern\" if int(d) >= 2000 else \"Legacy\")\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_single[\"era\"])  # Legacy=0, Modern=1\n",
    "\n",
    "# Step 4: Feature Engineering\n",
    "df_single[\"name\"] = df_single[\"name\"].str.lower()\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 3))\n",
    "X_ngram = vectorizer.fit_transform(df_single[\"name\"])\n",
    "\n",
    "df_single[\"length\"] = df_single[\"name\"].str.len()\n",
    "df_single[\"first_letter\"] = df_single[\"name\"].str[0]\n",
    "df_single[\"last_letter\"] = df_single[\"name\"].str[-1]\n",
    "df_single[\"ends_with_a\"] = (df_single[\"last_letter\"] == \"a\").astype(int)\n",
    "df_single[\"contains_y\"] = df_single[\"name\"].str.contains(\"y\").astype(int)\n",
    "df_single[\"ends_with_n\"] = (df_single[\"name\"].str[-1] == \"n\").astype(int)\n",
    "df_single[\"has_mc\"] = df_single[\"name\"].str.startswith(\"mc\").astype(int)\n",
    "df_single[\"vowel_ratio\"] = df_single[\"name\"].apply(lambda name: sum(c in \"aeiou\" for c in name) / len(name))\n",
    "df_single[\"suffix_2\"] = df_single[\"name\"].str[-2:]\n",
    "df_single[\"suffix_3\"] = df_single[\"name\"].str[-3:]\n",
    "total_per_decade = df_single.groupby(\"decade\")[\"total\"].transform(\"sum\")\n",
    "df_single[\"popularity_ratio\"] = df_single[\"total\"] / total_per_decade\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "X_suffix = ohe.fit_transform(df_single[[\"first_letter\", \"last_letter\", \"suffix_2\", \"suffix_3\"]])\n",
    "X_manual = df_single[[\n",
    "    \"length\", \"ends_with_a\", \"contains_y\", \"ends_with_n\",\n",
    "    \"has_mc\", \"vowel_ratio\", \"popularity_ratio\"\n",
    "]].astype(\"float32\").values\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "X_combined = csr_matrix(hstack([X_ngram, X_suffix, X_manual]))\n",
    "\n",
    "\n",
    "# Step 5: Stratified split with min Legacy constraint\n",
    "print(\"\\nCreating stratified split with minimum Legacy samples...\")\n",
    "sss = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "desired_min_legacy = 30\n",
    "found_split = False\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_combined, y):\n",
    "    if np.sum(y[test_idx] == 0) >= desired_min_legacy:\n",
    "        found_split = True\n",
    "        X_train = X_combined[train_idx]\n",
    "        X_test = X_combined[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test = y[test_idx]\n",
    "        print(f\"Test set includes {np.sum(y_test==0)} Legacy samples.\")\n",
    "        break\n",
    "\n",
    "if not found_split:\n",
    "    raise ValueError(\"Could not find a test split with enough Legacy samples.\")\n",
    "\n",
    "# Step 6: Oversample train set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 7: Train model (no scale_pos_weight)\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Step 8: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "print(\"Test Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
