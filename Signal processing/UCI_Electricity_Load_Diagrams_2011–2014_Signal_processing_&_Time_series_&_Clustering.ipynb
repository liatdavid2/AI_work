{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKT-Wh8jZgOR"
   },
   "source": [
    "# The dataset: ElectricityLoadDiagrams20112014 Dataset Explanation\n",
    "\n",
    "## Overview\n",
    "\n",
    "The file `LD2011_2014.txt` is the core file of the **ElectricityLoadDiagrams20112014** dataset. It contains detailed electricity consumption measurements for hundreds of clients, recorded at regular 15-minute intervals, spanning from **January 1, 2011** to **December 31, 2014**.\n",
    "\n",
    "This dataset is suitable for a wide range of **time series analysis** and **signal processing** tasks, including but not limited to:\n",
    "\n",
    "* Anomaly detection\n",
    "* Seasonality decomposition\n",
    "* Forecasting (short-term and long-term)\n",
    "* Customer segmentation\n",
    "* Load clustering\n",
    "* Energy demand profiling\n",
    "\n",
    "## Structure\n",
    "\n",
    "* **Rows**: Each row represents a single **timestamped reading**, recorded every **15 minutes**.\n",
    "* **Columns**: Each column corresponds to a **unique client/metre ID** (e.g., `MT_001`, `MT_002`, ...).\n",
    "* **Values**: Consumption values in **kilowatts (kW)**.\n",
    "\n",
    "Example of the raw format:\n",
    "\n",
    "| Timestamp           | MT_001 | MT_002 | MT_003 | ... |\n",
    "| ------------------- | ------ | ------ | ------ | --- |\n",
    "| 2011-01-01 00:15:00 | 1.118  | 1.055  | 1.175  | ... |\n",
    "| 2011-01-01 00:30:00 | 1.102  | 1.067  | 1.156  | ... |\n",
    "| ...                 | ...    | ...    | ...    | ... |\n",
    "\n",
    "\n",
    "## Time Range\n",
    "\n",
    "* **Start**: 2011-01-01 00:15:00\n",
    "* **End**: 2014-12-31 23:45:00\n",
    "* **Frequency**: Every 15 minutes\n",
    "* **Total Duration**: 4 full years\n",
    "\n",
    "## Data Characteristics\n",
    "\n",
    "* More than **370 clients/meters**\n",
    "* Some columns contain **missing values**, which should be filled using techniques like forward-fill or interpolation\n",
    "* Data can be **resampled** to hourly, daily, or weekly levels depending on the use case\n",
    "* Seasonal trends are clearly visible (e.g., daily/weekly cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-JuupfTVmpP",
    "outputId": "296f7c9e-0552-4521-bf0d-5adbd1f4f899"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qx5K8PzYju7"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the ZIP file in your Google Drive\n",
    "zip_path = \"/content/drive/MyDrive/Portfolio datasets/Signal processing/electricityloaddiagrams20112014.zip\"\n",
    "\n",
    "# Destination folder to extract to\n",
    "extract_path = \"/content/electricityLoadDiagrams20112014\"\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"Extracted to: {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsZXsHCWWOLL",
    "outputId": "7b2030a9-28d8-4240-ceb9-afeba00e73bb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Load the file\n",
    "# ----------------------------------------\n",
    "\n",
    "file_path = \"/content/electricityLoadDiagrams20112014/LD2011_2014.txt\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\";\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    decimal=\",\"\n",
    ")\n",
    "df.index.name = \"timestamp\"\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "print(\"Raw shape:\", df.shape)\n",
    "print(\"df:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvQ1a4WoWavv"
   },
   "source": [
    "#  Hourly data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MYl4H5SX672"
   },
   "source": [
    "# Hourly Electricity Consumption – 4 Random Clients (2011–2015)\n",
    "\n",
    "This chart visualizes the **hourly power consumption (in kW)** for four randomly selected clients from the dataset, over a 4-year period (2011–2015). Each line represents one client's consumption trend across time.\n",
    "\n",
    "---\n",
    "\n",
    "## Client Summaries:\n",
    "\n",
    "* **MT_249** (blue):\n",
    "  Moderate consumption with gradual growth until 2012, followed by irregular gaps and a sharp decline—likely a medium-scale commercial client or one with data quality issues.\n",
    "\n",
    "* **MT_214** (orange):\n",
    "  Extremely high and volatile usage with clear seasonal peaks and heavy load patterns—probably an industrial facility or large-scale enterprise.\n",
    "\n",
    "* **MT_015** (green):\n",
    "  Very low and stable consumption, showing little variation—likely a low-usage client such as a residential site or minimally active location.\n",
    "\n",
    "* **MT_059** (red):\n",
    "  Steady, medium-level consumption with periodic drops, indicating consistent operation punctuated by shutdowns or off-periods—possibly a manufacturing or logistics site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "3eAMQWIiXF5v",
    "outputId": "c0efee0a-e1a3-4ea8-fe7d-ef28f15ea7a6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Data cleaning\n",
    "# ----------------------------------------\n",
    "\n",
    "# Drop columns (clients) with more than 90% missing data\n",
    "df = df.dropna(axis=1, thresh=int(0.1 * len(df)))\n",
    "\n",
    "# Sort index to ensure time order\n",
    "df = df.sort_index()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Resample to hourly frequency (mean of 4×15min)\n",
    "# ----------------------------------------\n",
    "df_hourly = df.resample(\"1h\").mean()\n",
    "\n",
    "# Fill missing values using modern syntax\n",
    "df_hourly = df_hourly.ffill().bfill()\n",
    "\n",
    "print(\"Hourly shape:\", df_hourly.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Select 4 random clients and plot\n",
    "# ----------------------------------------\n",
    "\n",
    "random_clients = np.random.choice(df_hourly.columns, size=4, replace=False)\n",
    "print(\"Sample clients:\", random_clients)\n",
    "\n",
    "df_hourly[random_clients].plot(figsize=(15, 5), title=\"Hourly Electricity Consumption - 4 Random Clients\")\n",
    "plt.ylabel(\"kW\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL4GH6mIZ0Et"
   },
   "source": [
    "# Z-Score Anomaly Detection – 4 Clients Summary\n",
    "\n",
    "This analysis detects hourly electricity consumption anomalies for four clients using the **Z-Score method** with a threshold of **|Z| > 3σ**.\n",
    "\n",
    "Each client's time series is analyzed individually, and data points that deviate significantly from the mean (by more than 3 standard deviations) are marked as **anomalies**.\n",
    "\n",
    "Anomalies are highlighted as **red dots** on the respective time series plots, making it easy to visually identify unusual consumption spikes or drops.\n",
    "\n",
    "---\n",
    "\n",
    "## Methodology\n",
    "\n",
    "* The **Z-Score** is computed as:\n",
    "\n",
    "  $$\n",
    "  Z = \\frac{x - \\mu}{\\sigma}\n",
    "  $$\n",
    "\n",
    "  where:\n",
    "\n",
    "  * $x$: hourly consumption value\n",
    "  * $\\mu$: mean of the client’s entire time series\n",
    "  * $\\sigma$: standard deviation of the time series\n",
    "\n",
    "* A data point is labeled as an **anomaly** if:\n",
    "\n",
    "  $$\n",
    "  |Z| > 3\n",
    "  $$\n",
    "\n",
    "* This threshold identifies statistically rare events, assuming a normal distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualization\n",
    "\n",
    "* Each plot displays:\n",
    "\n",
    "  * The **hourly load signal** (blue line)\n",
    "  * The **anomalous points** (red dots)\n",
    "* Enables quick comparison of behavior across multiple clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "22MVt_-tYbmn",
    "outputId": "457b518f-23e5-4951-90c3-34d246130be8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Define the selected clients (same as in previous cell)\n",
    "selected_clients = ['MT_249', 'MT_214', 'MT_015', 'MT_059']\n",
    "\n",
    "# Plot settings\n",
    "fig, axes = plt.subplots(len(selected_clients), 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "for i, client in enumerate(selected_clients):\n",
    "    signal = df_hourly[client]\n",
    "    z_scores = zscore(signal, nan_policy='omit')\n",
    "    anomalies = np.abs(z_scores) > 3\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(signal.index, signal, label=\"Signal\")\n",
    "    ax.scatter(signal.index[anomalies], signal[anomalies], color='red', s=10, label=\"Anomalies (>3σ)\")\n",
    "    ax.set_title(f\"Anomaly Detection (Z-Score) – {client}\")\n",
    "    ax.set_ylabel(\"kW\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Timestamp\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs2n4RaQbgBN"
   },
   "source": [
    "# Frequency Analysis (FFT) – 4 Clients\n",
    "\n",
    "We used the **Fast Fourier Transform (FFT)** to analyze the hourly electricity usage of these clients:\n",
    "\n",
    "* `MT_249`, `MT_214`, `MT_015`, `MT_059`\n",
    "\n",
    "### What We Did:\n",
    "\n",
    "* Removed the average from each signal (detrending)\n",
    "* Applied FFT to move from **time domain** to **frequency domain**\n",
    "* Plotted only the **positive frequencies**\n",
    "* Showed the **amplitude** (strength) of each frequency\n",
    "\n",
    "---\n",
    "\n",
    "## What the Plots Show:\n",
    "\n",
    "* **X-axis**: Frequency (1/hour)\n",
    "* **Y-axis**: Amplitude of each frequency component\n",
    "* Peaks = **repeating patterns** in the signal\n",
    "\n",
    "---\n",
    "\n",
    "## Insights per Client:\n",
    "\n",
    "* **MT_249**: Strong low-frequency cycles, likely daily/weekly patterns\n",
    "* **MT_214**: Very strong and regular periodicity, possibly industrial usage\n",
    "* **MT_015**: Noticeable cycles, but less regular\n",
    "* **MT_059**: Many overlapping cycles, suggesting complex seasonal behavior\n",
    "\n",
    "---\n",
    "\n",
    "## Why FFT Is Useful:\n",
    "\n",
    "* Detects **seasonality and cycles**\n",
    "* Helps with **forecasting and clustering**\n",
    "* Highlights **hidden patterns** in the data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7Cfgm5BlaUTm",
    "outputId": "7880366f-d6c7-4eca-ca04-123212463d00"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the selected clients\n",
    "selected_clients = ['MT_249', 'MT_214', 'MT_015', 'MT_059']\n",
    "\n",
    "# Plot FFT spectrum for each client\n",
    "fig, axes = plt.subplots(len(selected_clients), 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "for i, client in enumerate(selected_clients):\n",
    "    signal = df_hourly[client]\n",
    "    detrended = signal - signal.mean()\n",
    "\n",
    "    fft_vals = np.fft.fft(detrended)\n",
    "    fft_freqs = np.fft.fftfreq(len(fft_vals), d=1)\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(fft_freqs[:len(fft_vals)//2], np.abs(fft_vals[:len(fft_vals)//2]))\n",
    "    ax.set_title(f\"FFT Spectrum – {client}\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.grid(True)\n",
    "\n",
    "axes[-1].set_xlabel(\"Frequency (1/hour)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKTymA8ddgsg"
   },
   "source": [
    "# Wavelet Transform – four clients\n",
    "\n",
    "We applied a **Wavelet Transform** using the **Daubechies 4 (db4)** wavelet on the hourly electricity consumption of four clients:\n",
    "\n",
    "* `MT_249`, `MT_214`, `MT_015`, `MT_059`\n",
    "\n",
    "Each signal was **decomposed into 4 levels**, and we plotted only the **detail coefficients** (D1–D4), which capture **short-term to mid-term changes**.\n",
    "\n",
    "---\n",
    "\n",
    "## Results Overview\n",
    "\n",
    "* **MT_249**: Strong early spikes in D1–D2, gradual shifts in D3–D4\n",
    "* **MT_214**: Very large, periodic patterns in D1–D2, stable D4\n",
    "* **MT_015**: Late activation; changes begin mid-series, clearly visible in D1–D2\n",
    "* **MT_059**: High-frequency bursts early on; long-term structure in D4\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "* D1–D4 help detect **sudden changes**, **anomalies**, and **pattern shifts**\n",
    "* Useful for **behavioral monitoring**, **segmentation**, and **feature extraction**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YRk1vA8XYMzn",
    "outputId": "997e141f-34c3-495f-e53e-c7ff7c831e66"
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the selected clients\n",
    "selected_clients = ['MT_249', 'MT_214', 'MT_015', 'MT_059']\n",
    "\n",
    "# Wavelet settings\n",
    "wavelet = 'db4'\n",
    "level = 4\n",
    "\n",
    "# Plot for each client\n",
    "for client in selected_clients:\n",
    "    signal = df_hourly[client].ffill()  # Fill for completeness\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "\n",
    "    # Skip the approximation (A4), plot only details D1–D4\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    for i, detail in enumerate(coeffs[1:], 1):\n",
    "        plt.plot(detail, label=f'Detail D{i}')\n",
    "\n",
    "    plt.title(f\"Wavelet Detail Coefficients – {client}\")\n",
    "    plt.xlabel(\"Wavelet Coefficient Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDAs3IA9eIou"
   },
   "source": [
    "# STL Decomposition – 4 Clients\n",
    "\n",
    "We used **STL (Seasonal-Trend decomposition using Loess)** to break down the daily electricity consumption of four clients:\n",
    "\n",
    "* `MT_249`, `MT_214`, `MT_015`, `MT_059`\n",
    "\n",
    "### What We Did:\n",
    "\n",
    "* Converted each hourly signal to **daily averages**\n",
    "* Used `STL()` with a **seasonal period of 13 days**\n",
    "* Decomposed each time series into:\n",
    "\n",
    "  * **Trend**: long-term behavior\n",
    "  * **Seasonal**: repeating short-term cycles\n",
    "  * **Residual**: irregular fluctuations (anomalies, noise)\n",
    "\n",
    "---\n",
    "\n",
    "## What the Plots Show:\n",
    "\n",
    "### **MT_249**\n",
    "\n",
    "* Clear long-term drop and recovery in trend\n",
    "* Regular seasonal dips\n",
    "* Residuals show scattered anomalies\n",
    "\n",
    "### **MT_214**\n",
    "\n",
    "* Strong seasonal patterns repeating every few months\n",
    "* Trend reflects structured industrial behavior\n",
    "* Residuals include several sharp spikes\n",
    "\n",
    "### **MT_015**\n",
    "\n",
    "* Flat before 2013, then sudden activation\n",
    "* Seasonality and anomalies appear only in later periods\n",
    "\n",
    "### **MT_059**\n",
    "\n",
    "* Usage begins sharply in 2012\n",
    "* Clear seasonal cycles and consistent long-term trend\n",
    "* Residuals highlight consumption spikes and outliers\n",
    "\n",
    "---\n",
    "\n",
    "STL helps us understand **how energy patterns change over time**, separating **expected cycles** from **unusual behavior**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "no2Ir7KseJEO",
    "outputId": "9a520d0b-94e8-4af4-8ac0-122d724c3193"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the selected clients\n",
    "selected_clients = ['MT_249', 'MT_214', 'MT_015', 'MT_059']\n",
    "\n",
    "# Make sure df_common includes only the selected clients\n",
    "df_common = df_hourly[selected_clients].copy()\n",
    "\n",
    "# Loop through each client and apply STL\n",
    "for client in selected_clients:\n",
    "    # Convert to daily signal\n",
    "    signal_daily = df_common[client].resample(\"1D\").mean().interpolate()\n",
    "\n",
    "    # Apply STL (seasonal period = 13 days)\n",
    "    stl = STL(signal_daily, seasonal=13)\n",
    "    result = stl.fit()\n",
    "\n",
    "    # Plot results\n",
    "    result.plot()\n",
    "    plt.suptitle(f\"STL Decomposition – {client}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ME9ZW_NfhsW"
   },
   "source": [
    "### Cluster All Clients by Daily Average Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-EKngheg24-"
   },
   "source": [
    "# Clustering Analysis Summary – Electricity Load Clients\n",
    "\n",
    "## 1. **Goal**\n",
    "\n",
    "We clustered clients based on their **daily electricity consumption patterns** to discover groups with similar behavior and identify outliers.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Elbow Method – Choosing k**\n",
    "\n",
    "We used the **Elbow Method** to choose the optimal number of clusters (`k`) by plotting **inertia** (within-cluster variance) for `k = 1 to 10`.\n",
    "\n",
    "* The **\"elbow point\"** was at **k = 3 or 4**\n",
    "* Beyond `k = 4`, improvements became minimal\n",
    "\n",
    "This guided us to test both **k = 3** and **k = 4**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Clustering with KMeans**\n",
    "\n",
    "We applied **KMeans clustering** using both:\n",
    "\n",
    "* `k = 3` (simple, clean separation)\n",
    "* `k = 4` (adds fine-grained cluster for rare clients)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Evaluation Metrics**\n",
    "\n",
    "We used 3 standard internal clustering metrics:\n",
    "\n",
    "### • Silhouette Score\n",
    "\n",
    "* Measures how well each client fits within its cluster\n",
    "* **Range:** -1 to 1\n",
    "* **Higher = Better separation**\n",
    "* Results:\n",
    "\n",
    "  * `k = 3`: **0.961**\n",
    "  * `k = 4`: **0.935**\n",
    "\n",
    "### • Calinski-Harabasz Score\n",
    "\n",
    "* Measures between-cluster dispersion\n",
    "* **Higher = Better structure**\n",
    "* Results:\n",
    "\n",
    "  * `k = 3`: 935.94\n",
    "  * `k = 4`: **1134.13**\n",
    "\n",
    "### • Davies-Bouldin Score\n",
    "\n",
    "* Measures cluster overlap\n",
    "* **Lower = Better**\n",
    "* Results:\n",
    "\n",
    "  * `k = 3`: **0.260**\n",
    "  * `k = 4`: 0.418\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Interpretation**\n",
    "\n",
    "* **k = 3**:\n",
    "\n",
    "  * High-quality separation\n",
    "  * Simple structure\n",
    "  * Good compactness\n",
    "\n",
    "* **k = 4**:\n",
    "\n",
    "  * Still excellent, but adds **more granularity**\n",
    "  * Helpful if you want to **analyze rare or outlier clients**\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| k | Silhouette | CH Score    | DB Score  | Notes                      |\n",
    "| - | ---------- | ----------- | --------- | -------------------------- |\n",
    "| 3 | **0.961**  | 935.94      | **0.260** | Best compact clustering    |\n",
    "| 4 | 0.935      | **1134.13** | 0.418     | Captures more rare clients |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixranlRSYIhX",
    "outputId": "27fb847e-7c4e-46ec-a513-6638928dd5c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Load and clean the file\n",
    "# -------------------------------\n",
    "file_path = \"/content/electricityLoadDiagrams20112014/LD2011_2014.txt\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\";\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    decimal=\",\"\n",
    ")\n",
    "df.index.name = \"timestamp\"\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "print(\"Raw shape:\", df.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Convert to hourly\n",
    "# -------------------------------\n",
    "df = df.sort_index()\n",
    "df_hourly = df.resample(\"1h\").mean().ffill().bfill()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Aggregate to daily (for clustering)\n",
    "# -------------------------------\n",
    "df_daily = df_hourly.resample(\"1D\").mean()\n",
    "\n",
    "# Transpose → shape (clients, days)\n",
    "daily_profiles = df_daily.T\n",
    "daily_profiles = daily_profiles.dropna(axis=0)  # Drop clients with missing values\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Clustering\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(daily_profiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "6WS0a5jQiJXF",
    "outputId": "4debc6bd-5ffe-4b92-c209-584150037cca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Elbow method: test different k values\n",
    "inertias = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    km.fit(X)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "# Plot Elbow Curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(K_range, inertias, marker='o')\n",
    "plt.title(\"Elbow Method – Optimal Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (within-cluster sum of squares)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(K_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KU-HJ6u4kcWl"
   },
   "source": [
    "# Three clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "yZhCWi_4iosN",
    "outputId": "5cf0098c-74db-4057-91aa-b7b87cf25a2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: KMeans with k=3\n",
    "# ----------------------------------------\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=\"auto\")\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Map client IDs to clusters\n",
    "# ----------------------------------------\n",
    "client_cluster_df = pd.DataFrame({\n",
    "    'ClientID': daily_profiles.index,\n",
    "    'Cluster': clusters\n",
    "})\n",
    "\n",
    "# Print how many clients in each cluster\n",
    "print(\"Client Count per Cluster:\")\n",
    "print(client_cluster_df['Cluster'].value_counts().sort_index())\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Evaluation metrics\n",
    "# ----------------------------------------\n",
    "sil_score = silhouette_score(X, clusters)\n",
    "ch_score = calinski_harabasz_score(X, clusters)\n",
    "db_score = davies_bouldin_score(X, clusters)\n",
    "\n",
    "print(\"\\nClustering Evaluation Metrics:\")\n",
    "print(f\"• Silhouette Score        : {sil_score:.3f}  (higher is better, max = 1)\")\n",
    "print(f\"• Calinski-Harabasz Score : {ch_score:.2f}   (higher is better)\")\n",
    "print(f\"• Davies-Bouldin Score    : {db_score:.3f}  (lower is better)\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: PCA Visualization\n",
    "# ----------------------------------------\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap=\"tab10\", s=10)\n",
    "plt.title(\"PCA Projection of Clusters (k=3)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "EEZzU0KwlEMo",
    "outputId": "22c2d740-1149-4609-a7e8-02c6f6d79a28"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: KMeans with k=4\n",
    "# ----------------------------------------\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=\"auto\")\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Map client IDs to clusters\n",
    "# ----------------------------------------\n",
    "client_cluster_df = pd.DataFrame({\n",
    "    'ClientID': daily_profiles.index,\n",
    "    'Cluster': clusters\n",
    "})\n",
    "\n",
    "# Print how many clients in each cluster\n",
    "print(\"Client Count per Cluster:\")\n",
    "print(client_cluster_df['Cluster'].value_counts().sort_index())\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Evaluation metrics\n",
    "# ----------------------------------------\n",
    "sil_score = silhouette_score(X, clusters)\n",
    "ch_score = calinski_harabasz_score(X, clusters)\n",
    "db_score = davies_bouldin_score(X, clusters)\n",
    "\n",
    "print(\"\\nClustering Evaluation Metrics:\")\n",
    "print(f\"• Silhouette Score        : {sil_score:.3f}  (higher is better, max = 1)\")\n",
    "print(f\"• Calinski-Harabasz Score : {ch_score:.2f}   (higher is better)\")\n",
    "print(f\"• Davies-Bouldin Score    : {db_score:.3f}  (lower is better)\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: PCA Visualization\n",
    "# ----------------------------------------\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap=\"tab10\", s=10)\n",
    "plt.title(\"PCA Projection of Clusters (k=4)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
