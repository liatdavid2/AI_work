{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9564de7",
   "metadata": {},
   "source": [
    "# FlowClus â€“ Clean Clustering Notebook for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"/content/netflow_sampling_250_50-50_train.csv\")\n",
    "df['duration'] = df['last'] - df['first']\n",
    "df['bytes_per_pkt'] = df['doctets'] / (df['dpkts'] + 1)\n",
    "\n",
    "features = ['dpkts', 'doctets', 'srcport', 'dstport', 'prot', 'tcp_flags', 'duration', 'bytes_per_pkt']\n",
    "X = df[features].fillna(0)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb50663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertias = []\n",
    "K = range(2, 10)\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X_scaled)\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(K, inertias, 'o-')\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Inertia (WCSS)\")\n",
    "plt.title(\"Elbow Method for KMeans\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, OPTICS, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def dunn_index(X, labels):\n",
    "    unique = np.unique(labels)\n",
    "    unique = unique[unique != -1]\n",
    "    if len(unique) < 2: return np.nan\n",
    "    intra, inter = [], []\n",
    "    for i in unique:\n",
    "        xi = X[labels == i]\n",
    "        if len(xi) > 1:\n",
    "            intra.append(np.max(cdist(xi, xi)))\n",
    "        for j in unique:\n",
    "            if i < j:\n",
    "                xj = X[labels == j]\n",
    "                inter.append(np.min(cdist(xi, xj)))\n",
    "    return np.min(inter) / np.max(intra)\n",
    "\n",
    "def beta_cv(X, labels):\n",
    "    D = pairwise_distances(X)\n",
    "    intra, inter = [], []\n",
    "    for i in np.unique(labels):\n",
    "        if i == -1: continue\n",
    "        idx = np.where(labels == i)[0]\n",
    "        if len(idx) > 1:\n",
    "            intra_d = D[np.ix_(idx, idx)]\n",
    "            intra.append(np.mean(intra_d[np.triu_indices_from(intra_d, k=1)]))\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i+1, len(X)):\n",
    "            if labels[i] != labels[j] and labels[i] != -1 and labels[j] != -1:\n",
    "                inter.append(D[i, j])\n",
    "    return np.mean(intra) / np.mean(inter)\n",
    "\n",
    "def evaluate_all(X, labels, name):\n",
    "    print(f\"=== {name} ===\")\n",
    "    if len(np.unique(labels)) <= 1 or np.all(labels == -1):\n",
    "        print(\"Not enough clusters.\")\n",
    "        return\n",
    "    print(f\"Silhouette Score        : {silhouette_score(X, labels):.3f}\")\n",
    "    print(f\"Davies-Bouldin Index    : {davies_bouldin_score(X, labels):.3f}\")\n",
    "    print(f\"Calinski-Harabasz Score : {calinski_harabasz_score(X, labels):.1f}\")\n",
    "    print(f\"Dunn Index              : {dunn_index(X, labels):.3f}\")\n",
    "    print(f\"BetaCV                  : {beta_cv(X, labels):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e876ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(X_scaled)\n",
    "df['kmeans'] = kmeans.labels_\n",
    "evaluate_all(X_scaled, kmeans.labels_, \"KMeans (k=4)\")\n",
    "\n",
    "# OPTICS\n",
    "optics = OPTICS(min_samples=10)\n",
    "optics_labels = optics.fit_predict(X_scaled)\n",
    "df['optics'] = optics_labels\n",
    "evaluate_all(X_scaled[optics_labels != -1], optics_labels[optics_labels != -1], \"OPTICS (excluding noise)\")\n",
    "\n",
    "# GMM\n",
    "gmm = GaussianMixture(n_components=4, random_state=42).fit(X_scaled)\n",
    "df['gmm'] = gmm.predict(X_scaled)\n",
    "evaluate_all(X_scaled, df['gmm'], \"Gaussian Mixture (k=4)\")\n",
    "\n",
    "# Agglomerative\n",
    "agglo = AgglomerativeClustering(n_clusters=4)\n",
    "df['agglo'] = agglo.fit_predict(X_scaled)\n",
    "evaluate_all(X_scaled, df['agglo'], \"Agglomerative Clustering (k=4)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99754c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"netflow_with_clusters_clean.csv\", index=False)\n",
    "print(\"Saved: netflow_with_clusters_clean.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
