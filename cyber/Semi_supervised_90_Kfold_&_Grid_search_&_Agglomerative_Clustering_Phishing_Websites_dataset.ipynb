{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqSx9_ywj61P",
    "outputId": "7baf812e-2c6d-497b-ce45-d86e3e01c2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWiTJ4dlZj8"
   },
   "source": [
    "# Phishing Websites Dataset – UCI Machine Learning Repository\n",
    "\n",
    "The Phishing Websites dataset, contributed by Rami Mohammad and Lee McCluskey in 2015, is designed for classifying websites as phishing or legitimate. It comprises 11,055 instances and 30 features, all represented as integers. The target variable, \"Result,\" indicates the website's status: `1` for legitimate, `0` for suspicious, and `-1` for phishing. The dataset was sourced from PhishTank, MillerSmiles, and Google's search operators. Notably, it does not contain missing values. :contentReference[oaicite:10]{index=10}:contentReference[oaicite:11]{index=11}\n",
    "\n",
    "Each feature in the dataset corresponds to specific attributes of a website's URL or domain, such as:​:contentReference[oaicite:14]{index=14}\n",
    "\n",
    "- Presence of an IP address in the URL\n",
    "- URL length\n",
    "- Use of shortening services\n",
    "- Presence of the \"@\" symbol\n",
    "- Double slash redirection\n",
    "- Prefix or suffix in the domain\n",
    "- Subdomain presence\n",
    "- SSL certificate status\n",
    "- Domain registration length\n",
    "- Favicon presence:contentReference[oaicite:35]{index=35}\n",
    "\n",
    "These features are instrumental in distinguishing phishing websites from legitimate ones. For a detailed description of each feature, refer to the [Phishing Websites Features document](https://archive.ics.uci.edu/ml/machine-learning-databases/00327/Phishing%20Websites%20Features.docx). :contentReference[oaicite:40]{index=40}\n",
    "\n",
    "This dataset is widely utilized in cybersecurity research and machine learning applications aimed at enhancing web security.:contentReference[oaicite:43]{index=43}\n",
    "\n",
    "For more information or to download the dataset, visit the [UCI Machine Learning Repository's Phishing Websites page](https://archive.ics.uci.edu/dataset/327/phishing+websites).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lseh3AJNj_gv",
    "outputId": "daa8a6a8-29f9-433b-fd79-bacda2df08bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Train size: (6633, 31)\n",
      "Validation size: (2211, 31)\n",
      "Test size: (2211, 31)\n"
     ]
    }
   ],
   "source": [
    "!pip install liac-arff --quiet\n",
    "\n",
    "import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === Path to the ARFF file inside the extracted ZIP\n",
    "arff_path = \"/content/phishing_dataset/Training Dataset.arff\"\n",
    "\n",
    "# === Load ARFF\n",
    "with open(arff_path, 'r') as f:\n",
    "    dataset = arff.load(f)\n",
    "\n",
    "# === Convert to DataFrame\n",
    "df = pd.DataFrame(dataset['data'], columns=[attr[0] for attr in dataset['attributes']])\n",
    "\n",
    "# === Convert target column (last column is usually 'Result')\n",
    "df['Result'] = df['Result'].astype(int).map({1: 0, -1: 1})  # 0 = Legitimate, 1 = Phishing\n",
    "\n",
    "# === Split to Train / Validation / Test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['Result'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Result'], random_state=42)\n",
    "\n",
    "print(f\"Train size: {train_df.shape}\")\n",
    "print(f\"Validation size: {val_df.shape}\")\n",
    "print(f\"Test size: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "6Yo-gUbZkv0X",
    "outputId": "522a536c-4f7e-46b7-c36f-de7bfc4bce50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['having_IP_Address', 'URL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page', 'Statistical_report', 'Result']\n",
      "\n",
      "Value counts for 'Result':\n",
      " Result\n",
      " 1    6157\n",
      "-1    4898\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b5c2525e-62f2-4e74-90de-9619a5e3bb48\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5c2525e-62f2-4e74-90de-9619a5e3bb48')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b5c2525e-62f2-4e74-90de-9619a5e3bb48 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b5c2525e-62f2-4e74-90de-9619a5e3bb48');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9b7af8e0-231c-486a-aeba-542f703cad41\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b7af8e0-231c-486a-aeba-542f703cad41')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9b7af8e0-231c-486a-aeba-542f703cad41 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  having_IP_Address URL_Length Shortining_Service having_At_Symbol  \\\n",
       "0                -1          1                  1                1   \n",
       "1                 1          1                  1                1   \n",
       "2                 1          0                  1                1   \n",
       "3                 1          0                  1                1   \n",
       "4                 1          0                 -1                1   \n",
       "\n",
       "  double_slash_redirecting Prefix_Suffix having_Sub_Domain SSLfinal_State  \\\n",
       "0                       -1            -1                -1             -1   \n",
       "1                        1            -1                 0              1   \n",
       "2                        1            -1                -1             -1   \n",
       "3                        1            -1                -1             -1   \n",
       "4                        1            -1                 1              1   \n",
       "\n",
       "  Domain_registeration_length Favicon  ... popUpWidnow Iframe age_of_domain  \\\n",
       "0                          -1       1  ...           1      1            -1   \n",
       "1                          -1       1  ...           1      1            -1   \n",
       "2                          -1       1  ...           1      1             1   \n",
       "3                           1       1  ...           1      1            -1   \n",
       "4                          -1       1  ...          -1      1            -1   \n",
       "\n",
       "  DNSRecord web_traffic Page_Rank Google_Index Links_pointing_to_page  \\\n",
       "0        -1          -1        -1            1                      1   \n",
       "1        -1           0        -1            1                      1   \n",
       "2        -1           1        -1            1                      0   \n",
       "3        -1           1        -1            1                     -1   \n",
       "4        -1           0        -1            1                      1   \n",
       "\n",
       "  Statistical_report Result  \n",
       "0                 -1     -1  \n",
       "1                  1     -1  \n",
       "2                 -1     -1  \n",
       "3                  1     -1  \n",
       "4                  1      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nValue counts for 'Result':\\n\", df['Result'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUG9nguz9vSD"
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6TbEGj1_uX5"
   },
   "source": [
    "# Semi-Supervised Clustering on Balanced Phishing Dataset Using Multiple Methods\n",
    "\n",
    "This code loads a phishing dataset, balances classes using oversampling, and extracts Catch22 features alongside XGBoost leaf index embeddings.  \n",
    "It combines these features and applies UMAP for dimensionality reduction.  \n",
    "**Three clustering algorithms—Gaussian Mixture Model, Agglomerative Clustering, and HDBSCAN***—are applied to the reduced features.  \n",
    "Clusters are mapped to true labels by majority vote, and evaluation metrics including classification report, Adjusted Rand Index (ARI), and Normalized Mutual Information (NMI) are printed for each method.  \n",
    "This provides a comparative analysis of clustering performance on semi-supervised phishing data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0eD6T-B2B4s",
    "outputId": "64252ed5-a1da-49b0-c17e-623b1a5fde98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GMM Clustering Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      6157\n",
      "           1       0.85      0.86      0.85      6157\n",
      "\n",
      "    accuracy                           0.85     12314\n",
      "   macro avg       0.85      0.85      0.85     12314\n",
      "weighted avg       0.85      0.85      0.85     12314\n",
      "\n",
      "ARI: 0.2936026942800383\n",
      "NMI: 0.30682773880430075\n",
      "\n",
      "--- Agglomerative Clustering Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86      6157\n",
      "           1       0.89      0.79      0.84      6157\n",
      "\n",
      "    accuracy                           0.85     12314\n",
      "   macro avg       0.85      0.85      0.85     12314\n",
      "weighted avg       0.85      0.85      0.85     12314\n",
      "\n",
      "ARI: 0.28490398634972514\n",
      "NMI: 0.2937189590729474\n",
      "\n",
      "--- HDBSCAN Clustering Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.88      0.90      0.89      6157\n",
      "           1       0.96      0.72      0.82      6157\n",
      "\n",
      "    accuracy                           0.81     12314\n",
      "   macro avg       0.61      0.54      0.57     12314\n",
      "weighted avg       0.92      0.81      0.86     12314\n",
      "\n",
      "ARI: 0.0746353510868623\n",
      "NMI: 0.24094244299310574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import hdbscan\n",
    "from xgboost import XGBClassifier\n",
    "from pycatch22 import catch22_all\n",
    "from umap import UMAP\n",
    "from scipy.stats import mode\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# === Load dataset ===\n",
    "data, meta = arff.loadarff(\"/content/phishing_dataset/Training Dataset.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "#df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "df = df.apply(lambda col: col.map(lambda x: x.decode() if isinstance(x, bytes) else x))\n",
    "\n",
    "df[\"Result\"] = df[\"Result\"].astype(int)\n",
    "\n",
    "# === Prepare data ===\n",
    "X = df.drop(columns=[\"Result\"]).astype(float)\n",
    "y = df[\"Result\"].astype(int)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
    "\n",
    "df_balanced = pd.DataFrame(X_balanced, columns=X.columns)\n",
    "df_balanced[\"Result\"] = y_balanced\n",
    "\n",
    "X_all = df_balanced.drop(columns=[\"Result\"]).astype(float)\n",
    "y_all = df_balanced[\"Result\"].astype(int)\n",
    "y_all_mapped = y_all.replace({-1:0, 1:1}).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "# === Catch22 features ===\n",
    "catch22_path = \"/content/catch22_feats.npy\"\n",
    "if os.path.exists(catch22_path):\n",
    "    catch22_feats = np.load(catch22_path)\n",
    "else:\n",
    "    catch22_feats = np.array([catch22_all(x.values)[\"values\"] for _, x in X_all.iterrows()])\n",
    "    np.save(catch22_path, catch22_feats)\n",
    "\n",
    "# === XGBoost embedding ===\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_all_scaled, y_all_mapped)\n",
    "\n",
    "leaf_indices = xgb.apply(X_all_scaled)\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "leaf_onehot = encoder.fit_transform(leaf_indices)\n",
    "\n",
    "# === Combine features ===\n",
    "X_combined = np.hstack([leaf_onehot, catch22_feats])\n",
    "\n",
    "# === UMAP reduction ===\n",
    "umap_model = UMAP(n_components=20, n_neighbors=30, min_dist=0.0)\n",
    "X_reduced = umap_model.fit_transform(X_combined)\n",
    "\n",
    "# === Clustering methods ===\n",
    "\n",
    "# 1. Gaussian Mixture Model (for comparison)\n",
    "gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "gmm_clusters = gmm.fit_predict(X_reduced)\n",
    "\n",
    "# 2. Agglomerative Clustering\n",
    "agglo = AgglomerativeClustering(n_clusters=4)\n",
    "agglo_clusters = agglo.fit_predict(X_reduced)\n",
    "\n",
    "# 3. HDBSCAN (no need to specify clusters count)\n",
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=50)\n",
    "hdbscan_clusters = hdbscan_clusterer.fit_predict(X_reduced)\n",
    "\n",
    "# === Map clusters to labels ===\n",
    "def map_clusters(true_labels, pred_clusters):\n",
    "    mapping = {}\n",
    "    for cluster_id in np.unique(pred_clusters):\n",
    "        if cluster_id == -1:  # HDBSCAN noise label\n",
    "            continue\n",
    "        majority = mode(true_labels[pred_clusters == cluster_id], keepdims=True).mode[0]\n",
    "        mapping[cluster_id] = majority\n",
    "    # For noise points in HDBSCAN assign -1 label\n",
    "    mapped = np.array([mapping.get(c, -1) for c in pred_clusters])\n",
    "    return mapped\n",
    "\n",
    "print(\"\\n--- GMM Clustering Evaluation ---\")\n",
    "mapped_gmm = map_clusters(y_all_mapped, gmm_clusters)\n",
    "print(classification_report(y_all_mapped, mapped_gmm))\n",
    "print(\"ARI:\", adjusted_rand_score(y_all_mapped, gmm_clusters))\n",
    "print(\"NMI:\", normalized_mutual_info_score(y_all_mapped, gmm_clusters))\n",
    "\n",
    "print(\"\\n--- Agglomerative Clustering Evaluation ---\")\n",
    "mapped_agglo = map_clusters(y_all_mapped, agglo_clusters)\n",
    "print(classification_report(y_all_mapped, mapped_agglo))\n",
    "print(\"ARI:\", adjusted_rand_score(y_all_mapped, agglo_clusters))\n",
    "print(\"NMI:\", normalized_mutual_info_score(y_all_mapped, agglo_clusters))\n",
    "\n",
    "print(\"\\n--- HDBSCAN Clustering Evaluation ---\")\n",
    "mapped_hdbscan = map_clusters(y_all_mapped, hdbscan_clusters)\n",
    "print(classification_report(y_all_mapped, mapped_hdbscan))\n",
    "print(\"ARI:\", adjusted_rand_score(y_all_mapped, hdbscan_clusters))\n",
    "print(\"NMI:\", normalized_mutual_info_score(y_all_mapped, hdbscan_clusters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq4iz0Od_O1w"
   },
   "source": [
    "# Semi-Supervised Clustering Pipeline with Grid Search on Phishing Dataset\n",
    "\n",
    "This code loads and balances a phishing dataset, extracting Catch22 features and generating XGBoost leaf index embeddings.  \n",
    "It combines these features, reduces their dimensionality using UMAP, and performs agglomerative clustering with different hyperparameters.  \n",
    "A grid search tests various numbers of clusters and linkage methods, mapping clusters to labels by majority vote.  \n",
    "Evaluation metrics including accuracy, macro F1, Adjusted Rand Index (ARI), and Normalized Mutual Information (NMI) are printed for each parameter combination.  \n",
    "The code is designed to identify the best clustering configuration for the balanced phishing data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQBWILi82w0i",
    "outputId": "43a564d8-7757-4b0c-dcf6-b4f9576980e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1883802367.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:38:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters=2, linkage=ward\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.263\n",
      "NMI: 0.228\n",
      "----------------------------------------\n",
      "n_clusters=2, linkage=complete\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.264\n",
      "NMI: 0.227\n",
      "----------------------------------------\n",
      "n_clusters=2, linkage=average\n",
      "Accuracy: 0.504\n",
      "Macro F1: 0.342\n",
      "ARI: 0.000\n",
      "NMI: 0.008\n",
      "----------------------------------------\n",
      "n_clusters=3, linkage=ward\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.205\n",
      "NMI: 0.185\n",
      "----------------------------------------\n",
      "n_clusters=3, linkage=complete\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.258\n",
      "NMI: 0.224\n",
      "----------------------------------------\n",
      "n_clusters=3, linkage=average\n",
      "Accuracy: 0.506\n",
      "Macro F1: 0.346\n",
      "ARI: 0.000\n",
      "NMI: 0.018\n",
      "----------------------------------------\n",
      "n_clusters=4, linkage=ward\n",
      "Accuracy: 0.875\n",
      "Macro F1: 0.875\n",
      "ARI: 0.341\n",
      "NMI: 0.344\n",
      "----------------------------------------\n",
      "n_clusters=4, linkage=complete\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.252\n",
      "NMI: 0.221\n",
      "----------------------------------------\n",
      "n_clusters=4, linkage=average\n",
      "Accuracy: 0.506\n",
      "Macro F1: 0.346\n",
      "ARI: 0.000\n",
      "NMI: 0.021\n",
      "----------------------------------------\n",
      "n_clusters=5, linkage=ward\n",
      "Accuracy: 0.898\n",
      "Macro F1: 0.898\n",
      "ARI: 0.370\n",
      "NMI: 0.385\n",
      "----------------------------------------\n",
      "n_clusters=5, linkage=complete\n",
      "Accuracy: 0.757\n",
      "Macro F1: 0.752\n",
      "ARI: 0.226\n",
      "NMI: 0.213\n",
      "----------------------------------------\n",
      "n_clusters=5, linkage=average\n",
      "Accuracy: 0.511\n",
      "Macro F1: 0.358\n",
      "ARI: 0.000\n",
      "NMI: 0.030\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from umap import UMAP\n",
    "from scipy.stats import mode\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier\n",
    "from pycatch22 import catch22_all\n",
    "\n",
    "# === Load dataset ===\n",
    "data_path = \"/content/phishing_dataset/Training Dataset.arff\"\n",
    "data, meta = arff.loadarff(data_path)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "df[\"Result\"] = df[\"Result\"].astype(int)\n",
    "\n",
    "# === Prepare balanced data ===\n",
    "X = df.drop(columns=[\"Result\"]).astype(float)\n",
    "y = df[\"Result\"].astype(int)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_bal, y_bal = ros.fit_resample(X, y)\n",
    "df_bal = pd.DataFrame(X_bal, columns=X.columns)\n",
    "df_bal[\"Result\"] = y_bal\n",
    "X_all = df_bal.drop(columns=[\"Result\"]).astype(float)\n",
    "y_all = df_bal[\"Result\"].astype(int)\n",
    "y_all_mapped = y_all.replace({-1:0, 1:1}).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "# === Catch22 features ===\n",
    "catch22_path = \"/content/catch22_feats.npy\"\n",
    "if os.path.exists(catch22_path):\n",
    "    catch22_feats = np.load(catch22_path)\n",
    "else:\n",
    "    catch22_feats = np.array([catch22_all(x.values)[\"values\"] for _, x in X_all.iterrows()])\n",
    "    np.save(catch22_path, catch22_feats)\n",
    "\n",
    "# === XGBoost embedding ===\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1,\n",
    "                    use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_all_scaled, y_all_mapped)\n",
    "leaf_indices = xgb.apply(X_all_scaled)\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "leaf_onehot = encoder.fit_transform(leaf_indices)\n",
    "\n",
    "# === Combine features ===\n",
    "X_combined = np.hstack([leaf_onehot, catch22_feats])\n",
    "\n",
    "# === UMAP reduction ===\n",
    "umap_model = UMAP(n_components=20, n_neighbors=30, min_dist=0.0, random_state=42)\n",
    "X_reduced = umap_model.fit_transform(X_combined)\n",
    "\n",
    "# === Grid Search parameters ===\n",
    "agglo_params = {\n",
    "    \"n_clusters\": [2, 3, 4, 5],\n",
    "    \"linkage\": [\"ward\", \"complete\", \"average\"]\n",
    "}\n",
    "\n",
    "# === Cluster-label mapping function ===\n",
    "def map_clusters_to_labels(true_labels, predicted_clusters):\n",
    "    mapping = {}\n",
    "    for cluster_id in np.unique(predicted_clusters):\n",
    "        majority = mode(true_labels[predicted_clusters == cluster_id], keepdims=True).mode[0]\n",
    "        mapping[cluster_id] = majority\n",
    "    return np.vectorize(mapping.get)(predicted_clusters)\n",
    "\n",
    "for n_clusters in agglo_params[\"n_clusters\"]:\n",
    "    for linkage in agglo_params[\"linkage\"]:\n",
    "        # ward linkage requires euclidean metric by default, no need to specify metric explicitly\n",
    "        try:\n",
    "            agglo = AgglomerativeClustering(\n",
    "                n_clusters=n_clusters,\n",
    "                linkage=linkage\n",
    "            )\n",
    "            clusters = agglo.fit_predict(X_reduced)\n",
    "            mapped_preds = map_clusters_to_labels(y_all_mapped, clusters)\n",
    "            report = classification_report(y_all_mapped, mapped_preds, output_dict=True, zero_division=0)\n",
    "            ari = adjusted_rand_score(y_all_mapped, clusters)\n",
    "            nmi = normalized_mutual_info_score(y_all_mapped, clusters)\n",
    "\n",
    "            print(f\"n_clusters={n_clusters}, linkage={linkage}\")\n",
    "            print(f\"Accuracy: {report['accuracy']:.3f}\")\n",
    "            print(f\"Macro F1: {report['macro avg']['f1-score']:.3f}\")\n",
    "            print(f\"ARI: {ari:.3f}\")\n",
    "            print(f\"NMI: {nmi:.3f}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping n_clusters={n_clusters}, linkage={linkage} due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER0sG4hu6Apu"
   },
   "source": [
    "# Semi-Supervised Clustering with K-Fold Cross-Validation on Phishing Dataset\n",
    "\n",
    "This code performs a 5-fold cross-validation semi-supervised clustering pipeline on a phishing dataset.  \n",
    "It balances training data via oversampling, extracts Catch22 features and XGBoost leaf embeddings, then reduces dimensionality with UMAP.  \n",
    "Agglomerative clustering with ward linkage is applied on the test set embeddings, and clusters are mapped to labels by majority vote.  \n",
    "Evaluation metrics including classification report, Adjusted Rand Index (ARI), and Normalized Mutual Information (NMI) are computed and printed for each fold and summarized at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJS3Di0C47bS",
    "outputId": "085056b0-e6ca-4a8e-ac34-eb616aee5c49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3441817568.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:42:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       956\n",
      "           1       0.93      0.94      0.93      1255\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "ARI: 0.389\n",
      "NMI: 0.436\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:43:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       950\n",
      "           1       0.90      0.92      0.91      1261\n",
      "\n",
      "    accuracy                           0.89      2211\n",
      "   macro avg       0.89      0.89      0.89      2211\n",
      "weighted avg       0.89      0.89      0.89      2211\n",
      "\n",
      "ARI: 0.325\n",
      "NMI: 0.394\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:44:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       997\n",
      "           1       0.89      0.94      0.91      1214\n",
      "\n",
      "    accuracy                           0.90      2211\n",
      "   macro avg       0.90      0.90      0.90      2211\n",
      "weighted avg       0.90      0.90      0.90      2211\n",
      "\n",
      "ARI: 0.379\n",
      "NMI: 0.413\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:45:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       985\n",
      "           1       0.92      0.95      0.93      1226\n",
      "\n",
      "    accuracy                           0.93      2211\n",
      "   macro avg       0.93      0.92      0.93      2211\n",
      "weighted avg       0.93      0.93      0.93      2211\n",
      "\n",
      "ARI: 0.431\n",
      "NMI: 0.463\n",
      "\n",
      "=== Fold 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [11:47:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      1010\n",
      "           1       0.89      0.93      0.91      1201\n",
      "\n",
      "    accuracy                           0.90      2211\n",
      "   macro avg       0.90      0.90      0.90      2211\n",
      "weighted avg       0.90      0.90      0.90      2211\n",
      "\n",
      "ARI: 0.357\n",
      "NMI: 0.406\n",
      "\n",
      "=== K-Fold Cross Validation Summary ===\n",
      "   fold  accuracy  macro_f1       ARI       NMI\n",
      "0     1  0.922659  0.921047  0.389057  0.436229\n",
      "1     2  0.894618  0.891972  0.324911  0.394130\n",
      "2     3  0.899593  0.897823  0.379238  0.413330\n",
      "3     4  0.926278  0.925128  0.430683  0.463483\n",
      "4     5  0.898688  0.897450  0.356836  0.405711\n",
      "Mean metrics:\n",
      "fold        3.000000\n",
      "accuracy    0.908367\n",
      "macro_f1    0.906684\n",
      "ARI         0.376145\n",
      "NMI         0.422577\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from umap import UMAP\n",
    "from scipy.stats import mode\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier\n",
    "from pycatch22 import catch22_all\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# === Load dataset ===\n",
    "data_path = \"/content/phishing_dataset/Training Dataset.arff\"\n",
    "data, meta = arff.loadarff(data_path)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "df[\"Result\"] = df[\"Result\"].astype(int)\n",
    "\n",
    "# === Prepare X and y ===\n",
    "X = df.drop(columns=[\"Result\"]).astype(float)\n",
    "y = df[\"Result\"].astype(int)\n",
    "y_mapped = y.replace({-1:0, 1:1}).values\n",
    "\n",
    "# === Initialize KFold ===\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# === Function to map clusters to labels ===\n",
    "def map_clusters_to_labels(true_labels, pred_clusters):\n",
    "    mapping = {}\n",
    "    for cluster_id in np.unique(pred_clusters):\n",
    "        majority = mode(true_labels[pred_clusters == cluster_id], keepdims=True).mode[0]\n",
    "        mapping[cluster_id] = majority\n",
    "    return np.vectorize(mapping.get)(pred_clusters)\n",
    "\n",
    "# === Store metrics per fold ===\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Split train/test\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y_mapped[train_idx], y_mapped[test_idx]\n",
    "\n",
    "    # Oversample training only\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "    X_train_bal = pd.DataFrame(X_train_bal, columns=X_train.columns)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_bal)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Catch22 features\n",
    "    catch22_train = np.array([catch22_all(row.values)[\"values\"] for _, row in X_train_bal.iterrows()])\n",
    "    catch22_test = np.array([catch22_all(row.values)[\"values\"] for _, row in X_test.iterrows()])\n",
    "\n",
    "    # XGBoost embedding - train classifier on balanced train data\n",
    "    xgb = XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, eval_metric='logloss', random_state=42)\n",
    "    xgb.fit(X_train_scaled, y_train_bal)\n",
    "    train_leaves = xgb.apply(X_train_scaled)\n",
    "    test_leaves = xgb.apply(X_test_scaled)\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    train_leaf_onehot = encoder.fit_transform(train_leaves)\n",
    "    test_leaf_onehot = encoder.transform(test_leaves)\n",
    "\n",
    "    # Combine features\n",
    "    X_train_combined = np.hstack([train_leaf_onehot, catch22_train])\n",
    "    X_test_combined = np.hstack([test_leaf_onehot, catch22_test])\n",
    "\n",
    "    # UMAP reduction (fit on train, transform test)\n",
    "    umap_model = UMAP(n_components=20, n_neighbors=30, min_dist=0.0, random_state=42)\n",
    "    X_train_reduced = umap_model.fit_transform(X_train_combined)\n",
    "    X_test_reduced = umap_model.transform(X_test_combined)\n",
    "\n",
    "    # Agglomerative clustering on test set\n",
    "    agglo = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
    "    clusters_test = agglo.fit_predict(X_test_reduced)\n",
    "\n",
    "    # Map clusters to labels using test true labels\n",
    "    mapped_test_preds = map_clusters_to_labels(y_test, clusters_test)\n",
    "\n",
    "    # Evaluation\n",
    "    report = classification_report(y_test, mapped_test_preds, output_dict=True, zero_division=0)\n",
    "    ari = adjusted_rand_score(y_test, clusters_test)\n",
    "    nmi = normalized_mutual_info_score(y_test, clusters_test)\n",
    "\n",
    "    print(classification_report(y_test, mapped_test_preds, zero_division=0))\n",
    "    print(f\"ARI: {ari:.3f}\")\n",
    "    print(f\"NMI: {nmi:.3f}\")\n",
    "\n",
    "    fold_metrics.append({\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"ARI\": ari,\n",
    "        \"NMI\": nmi\n",
    "    })\n",
    "\n",
    "# === Summary ===\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "print(\"\\n=== K-Fold Cross Validation Summary ===\")\n",
    "print(df_metrics)\n",
    "print(\"Mean metrics:\")\n",
    "print(df_metrics.mean())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
