{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_-mHPNrCuTe",
    "outputId": "bd5a9e36-2a47-4468-e6bd-79d11299931a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qY8qVKhQDLvw"
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes accelerate transformers langgraph"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQyf1Be2Itwn"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\"env\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZgFCo5xD7J-"
   },
   "outputs": [],
   "source": [
    "# === Open Source Granite 8B model LLM ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "try:\n",
    "    # Granite 8B model name on Hugging Face\n",
    "    GRANITE_MODEL = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "\n",
    "    # Load the model + tokenizer\n",
    "    granite_model = AutoModelForCausalLM.from_pretrained(\n",
    "        GRANITE_MODEL,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config  # Optional\n",
    "    )\n",
    "\n",
    "    granite_tokenizer = AutoTokenizer.from_pretrained(GRANITE_MODEL)\n",
    "\n",
    "    # Create pipeline\n",
    "    granite_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=granite_model,\n",
    "        tokenizer=granite_tokenizer,\n",
    "        pad_token_id=granite_tokenizer.eos_token_id,\n",
    "        return_full_text=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"[Warning] Failed to load LLaMA model:\", e)\n",
    "    granite_pipe = lambda prompt, **kwargs: [{\"generated_text\": \"[granit model unavailable]\"}]\n",
    "granite_pipe = pipeline(\"text-generation\", model=granite_model, tokenizer=granite_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdN3bP5YGKQw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Path to the ZIP file in Google Drive ===\n",
    "drive_zip_path = \"/content/drive/MyDrive/Portfolio datasets/vision/saadhaxxan_germantrafficsigns_kaggle.zip\"\n",
    "extract_path = \"/content/gtsrb_extracted\"\n",
    "\n",
    "# === Create extraction directory if it doesn't exist ===\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# === Unzip the file ===\n",
    "with zipfile.ZipFile(drive_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"✅ Unzipped into: {extract_path}\")\n",
    "\n",
    "# === List all files in the extracted folder ===\n",
    "print(\"📂 Files:\")\n",
    "print(os.listdir(extract_path))\n",
    "\n",
    "# === Function to load GTSRB Pickle files ===\n",
    "def load_gtsrb_pickle(filename):\n",
    "    with open(os.path.join(extract_path, filename), mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    X = data['features']  # images, shape: (N, 32, 32, 3)\n",
    "    y = data['labels']    # list of class indices\n",
    "    return X, y\n",
    "\n",
    "# === Load test set ===\n",
    "X_test, y_test = load_gtsrb_pickle(\"test.p\")\n",
    "\n",
    "# === Print dataset shapes ===\n",
    "print(f\"Test : {X_test.shape}, Labels: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfF3ipWQOvQO"
   },
   "source": [
    "# AI Agents for Traffic Sign Classification and Explanation\n",
    "\n",
    "This script uses two AI agents in a LangGraph pipeline:\n",
    "\n",
    "- **ClassifyImage Agent**: Uses a pretrained `MobileNetV2` model to classify a traffic sign image from the GTSRB dataset.\n",
    "- **ExplainAgent**: Uses `granite_pipe` to generate a **short natural-language explanation** (max 7 words) for the predicted sign.\n",
    "\n",
    "The agents communicate via a shared `AgentState`, and the system runs on 5 random test images.\n",
    "\n",
    "The explanation prompt is carefully crafted to ensure concise output:\n",
    "> `'Sign name' sign – explain in plain sentence, max 7 words, no bullets, no numbers.`\n",
    "\n",
    "This enables interpretable and human-readable AI behavior in traffic sign recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpDPo3g_KRrP"
   },
   "source": [
    "# Short explanation on 5 words - can save tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKTO7CWiJwtO",
    "outputId": "21378872-20d4-4895-bf75-9a612e35ba8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "📷 Image Index     : 7391\n",
      "🏷️ Model Prediction: Ahead only\n",
      "📘 Original Label  : Ahead only\n",
      "🧠 Explanation     : This sign warns drivers to keep right, avoiding intersections\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "📷 Image Index     : 9229\n",
      "🏷️ Model Prediction: No overtaking for trucks\n",
      "📘 Original Label  : No overtaking for trucks\n",
      "🧠 Explanation     : \"Trucks cannot pass other vehicles on this road.\"\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "📷 Image Index     : 9036\n",
      "🏷️ Model Prediction: Children crossing\n",
      "📘 Original Label  : Children crossing\n",
      "🧠 Explanation     : 'Warning: Children may be crossing.'\n",
      "\n",
      "## Instruction\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "📷 Image Index     : 5592\n",
      "🏷️ Model Prediction: Speed Limit 50\n",
      "📘 Original Label  : Speed Limit 50\n",
      "🧠 Explanation     : \"Drive at a maximum of fifty within this zone.\"\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "📷 Image Index     : 3327\n",
      "🏷️ Model Prediction: Yield\n",
      "📘 Original Label  : Yield\n",
      "🧠 Explanation     : A 'Yield' sign indicates drivers must give way to traffic already\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "# === Class labels (43 classes) ===\n",
    "class_labels = [\n",
    "    'Speed Limit 20', 'Speed Limit 30', 'Speed Limit 50', 'Speed Limit 60',\n",
    "    'Speed Limit 70', 'Speed Limit 80', 'End of Speed Limit 80', 'Speed Limit 100',\n",
    "    'Speed Limit 120', 'No overtaking', 'No overtaking for trucks', 'Right-of-way at intersection',\n",
    "    'Priority road', 'Yield', 'Stop Sign', 'No vehicles', 'No trucks', 'No entry',\n",
    "    'General caution', 'Dangerous curve left', 'Dangerous curve right', 'Double curve',\n",
    "    'Bumpy road', 'Slippery road', 'Road narrows', 'Construction', 'Traffic signals',\n",
    "    'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Snow', 'Animals',\n",
    "    'End of all restrictions', 'Turn right ahead', 'Turn left ahead', 'Ahead only',\n",
    "    'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left',\n",
    "    'Roundabout', 'End of no overtaking', 'End of no overtaking for trucks'\n",
    "]\n",
    "\n",
    "# === Load model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.mobilenet_v2(weights=None)\n",
    "model.classifier[1] = nn.Linear(model.last_channel, len(class_labels))\n",
    "model_path = \"/content/drive/MyDrive/Models/mobilenet_43classes_f1_0.915.pt\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === Image transform (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === Load test.p ===\n",
    "with open(\"/content/gtsrb_extracted/test.p\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X = test_data[\"features\"]\n",
    "y = test_data[\"labels\"]\n",
    "\n",
    "# === LangGraph State ===\n",
    "class AgentState(TypedDict):\n",
    "    image_index: int\n",
    "    model_prediction: str\n",
    "    original_label: str\n",
    "    explanation: str\n",
    "\n",
    "# === AI Agent: classify image using MobileNetV2 ===\n",
    "def classify_image_agent(state: AgentState) -> AgentState:\n",
    "    idx = state[\"image_index\"]\n",
    "    img_array = X[idx]\n",
    "    label_id = y[idx]\n",
    "    original_label = class_labels[label_id]\n",
    "\n",
    "    image = Image.fromarray(img_array).convert(\"RGB\").resize((64, 64))\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_id = output.argmax(dim=1).item()\n",
    "        predicted_label = class_labels[pred_id]\n",
    "\n",
    "    return {\n",
    "        \"image_index\": idx,\n",
    "        \"model_prediction\": predicted_label,\n",
    "        \"original_label\": original_label,\n",
    "        \"explanation\": \"\"  # will be filled in next step\n",
    "    }\n",
    "\n",
    "# === AI Agent: generate explanation using granite_pipe ===\n",
    "def explain_agent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"'{state['model_prediction']}' sign – explain in plain sentence, max 7 words, no bullets, no numbers, English only.\"\"\"\n",
    "    explanation = granite_pipe(prompt, max_new_tokens=15)[0]['generated_text']\n",
    "    state[\"explanation\"] = explanation.strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "# === LangGraph definition ===\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"ClassifyImage\", classify_image_agent)\n",
    "graph.add_node(\"ExplainAgent\", explain_agent)\n",
    "graph.set_entry_point(\"ClassifyImage\")\n",
    "graph.add_edge(\"ClassifyImage\", \"ExplainAgent\")\n",
    "graph.set_finish_point(\"ExplainAgent\")\n",
    "graph = graph.compile()\n",
    "\n",
    "# === Run agent on 5 random images ===\n",
    "indices = random.sample(range(len(X)), 5)\n",
    "\n",
    "for idx in indices:\n",
    "    result = graph.invoke({\"image_index\": idx})\n",
    "    print(\"\\n=== Traffic Sign AI Agent Result ===\")\n",
    "    print(f\"📷 Image Index     : {result['image_index']}\")\n",
    "    print(f\"🏷️ Model Prediction: {result['model_prediction']}\")\n",
    "    print(f\"📘 Original Label  : {result['original_label']}\")\n",
    "    print(f\"🧠 Explanation     : {result['explanation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et4s2wM8P4x9"
   },
   "source": [
    "### Long Explanation with Steps Prompt\n",
    "\n",
    "The prompt was modified to instruct the LLM to return a **clear, step-by-step explanation** for the predicted traffic sign. It generates **2–5 concise numbered steps** to guide the driver, ensuring structured and helpful instructions with no generic introductions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgLV-WenJwq-",
    "outputId": "86e7bb8f-bada-432b-a77d-266029990397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "🏷️ Model Prediction: Right-of-way at intersection\n",
      "📘 Original Label  : Right-of-way at intersection\n",
      "🧠 Explanation     :\n",
      "1. Approach the intersection slowly and cautiously, observing all traffic signs and signals.\n",
      "2. Identify if you have a stop sign or a yield sign. If you do, come to a complete stop before the stop line or yield line.\n",
      "3. Check for oncoming vehicles and pedestrians crossing or waiting to cross.\n",
      "4. Proceed with caution when it is safe to do so, ensuring that no other vehicles or pedestrians are crossing or entering the intersection.\n",
      "5. Continue through the intersection, maintaining a safe speed and staying in your lane.\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "🏷️ Model Prediction: End of Speed Limit 80\n",
      "📘 Original Label  : End of Speed Limit 80\n",
      "🧠 Explanation     :\n",
      "1. Upon seeing the 'End of Speed Limit 80' sign, the driver should immediately prepare to reduce their speed gradually.\n",
      "2. Locate the new speed limit sign ahead, which will indicate the reduced speed limit for the upcoming road segment.\n",
      "3. As you approach and pass the new speed limit sign, adjust the vehicle's speed accordingly to match the new speed limit.\n",
      "4. Maintain a safe following distance from the vehicle in front and be aware of any changes in road conditions that may require further speed adjustments.\n",
      "5. Always adhere to the posted speed limits and drive defensively, anticipating potential hazards and adjusting your speed as necessary.\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "🏷️ Model Prediction: End of no overtaking\n",
      "📘 Original Label  : Priority road\n",
      "🧠 Explanation     :\n",
      "1. Slow down and decrease your speed to match the flow of traffic.\n",
      "2. Position your vehicle in the right lane, as overtaking will no longer be permitted.\n",
      "3. Maintain a safe following distance from the vehicle ahead to avoid any potential collisions.\n",
      "4. Avoid changing lanes or overtaking any vehicles, as the 'No Overtaking' zone has now ended.\n",
      "5. Continue driving cautiously, paying attention to other traffic signs and signals along your route.\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "🏷️ Model Prediction: Turn left ahead\n",
      "📘 Original Label  : Turn left ahead\n",
      "🧠 Explanation     :\n",
      "1. Begin by slowing down and checking your mirrors to ensure it's safe to turn.\n",
      "2. Signal your intention to turn left using your indicator lights.\n",
      "3. Cautiously proceed into the left lane, if necessary, to prepare for the turn.\n",
      "4. When it's safe and you've cleared oncoming traffic, make the left turn.\n",
      "5. After completing the turn, ensure you're fully in the new lane and turn off your indicator.\n",
      "\n",
      "=== Traffic Sign AI Agent Result ===\n",
      "🏷️ Model Prediction: Keep right\n",
      "📘 Original Label  : Keep right\n",
      "🧠 Explanation     :\n",
      "1. Identify the sign: Recognize the 'Keep right' sign posted on the road.\n",
      "2. Position the vehicle: Ensure your vehicle is in the left lane if you are not already in the rightmost lane.\n",
      "3. Maintain lane: Stay in the right lane if you are already positioned there, and do not move left unless passing another vehicle.\n",
      "4. Pass safely: If you need to pass another vehicle, complete the pass quickly and safely, then signal and move back into the right lane.\n",
      "5. Comply with local regulations: Follow all local traffic laws and regulations, as some areas may have specific rules for keeping right.\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "# === Class labels (43 classes) ===\n",
    "class_labels = [\n",
    "    'Speed Limit 20', 'Speed Limit 30', 'Speed Limit 50', 'Speed Limit 60',\n",
    "    'Speed Limit 70', 'Speed Limit 80', 'End of Speed Limit 80', 'Speed Limit 100',\n",
    "    'Speed Limit 120', 'No overtaking', 'No overtaking for trucks', 'Right-of-way at intersection',\n",
    "    'Priority road', 'Yield', 'Stop Sign', 'No vehicles', 'No trucks', 'No entry',\n",
    "    'General caution', 'Dangerous curve left', 'Dangerous curve right', 'Double curve',\n",
    "    'Bumpy road', 'Slippery road', 'Road narrows', 'Construction', 'Traffic signals',\n",
    "    'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Snow', 'Animals',\n",
    "    'End of all restrictions', 'Turn right ahead', 'Turn left ahead', 'Ahead only',\n",
    "    'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left',\n",
    "    'Roundabout', 'End of no overtaking', 'End of no overtaking for trucks'\n",
    "]\n",
    "\n",
    "# === Load model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.mobilenet_v2(weights=None)\n",
    "model.classifier[1] = nn.Linear(model.last_channel, len(class_labels))\n",
    "model_path = \"/content/drive/MyDrive/Models/mobilenet_43classes_f1_0.915.pt\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === Image transform (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === Load test.p ===\n",
    "with open(\"/content/gtsrb_extracted/test.p\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X = test_data[\"features\"]\n",
    "y = test_data[\"labels\"]\n",
    "\n",
    "# === LangGraph State ===\n",
    "class AgentState(TypedDict):\n",
    "    image_index: int\n",
    "    model_prediction: str\n",
    "    original_label: str\n",
    "    explanation: str\n",
    "\n",
    "# === AI Agent: classify image using MobileNetV2 ===\n",
    "def classify_image_agent(state: AgentState) -> AgentState:\n",
    "    idx = state[\"image_index\"]\n",
    "    img_array = X[idx]\n",
    "    label_id = y[idx]\n",
    "    original_label = class_labels[label_id]\n",
    "\n",
    "    image = Image.fromarray(img_array).convert(\"RGB\").resize((64, 64))\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_id = output.argmax(dim=1).item()\n",
    "        predicted_label = class_labels[pred_id]\n",
    "\n",
    "    return {\n",
    "        \"image_index\": idx,\n",
    "        \"model_prediction\": predicted_label,\n",
    "        \"original_label\": original_label,\n",
    "        \"explanation\": \"\"  # will be filled in next step\n",
    "    }\n",
    "\n",
    "# === AI Agent: generate explanation using granite_pipe ===\n",
    "def explain_agent(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "      You are an expert traffic instructor.\n",
    "\n",
    "      Given the traffic sign: '{state['model_prediction']}', explain clearly and step-by-step what a driver should do.\n",
    "\n",
    "      Use a numbered list of 2 to 5 steps. Be concise and clear.\n",
    "\n",
    "      Avoid introductions or disclaimers. Respond in English only.\n",
    "      \"\"\"\n",
    "\n",
    "    explanation = granite_pipe(prompt, max_new_tokens=150)[0]['generated_text']\n",
    "    state[\"explanation\"] = explanation.strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "# === LangGraph definition ===\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"ClassifyImage\", classify_image_agent)\n",
    "graph.add_node(\"ExplainAgent\", explain_agent)\n",
    "graph.set_entry_point(\"ClassifyImage\")\n",
    "graph.add_edge(\"ClassifyImage\", \"ExplainAgent\")\n",
    "graph.set_finish_point(\"ExplainAgent\")\n",
    "graph = graph.compile()\n",
    "\n",
    "# === Run agent on 5 random images ===\n",
    "indices = random.sample(range(len(X)), 5)\n",
    "\n",
    "for idx in indices:\n",
    "    result = graph.invoke({\"image_index\": idx})\n",
    "    print(\"\\n=== Traffic Sign AI Agent Result ===\")\n",
    "    print(f\"🏷️ Model Prediction: {result['model_prediction']}\")\n",
    "    print(f\"📘 Original Label  : {result['original_label']}\")\n",
    "    explanation_lines = \"\\n\".join(result[\"explanation\"].splitlines())\n",
    "    print(f\"🧠 Explanation     :\\n{explanation_lines}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
